{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris dataset\n",
    "* Get sample data [here](https://github.com/fuyu-quant/IBLM/tree/main/datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/IBLM/blob/main/examples/iblmodel_iris.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/fuyu-quant/IBLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.15\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution('IBLM').version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from iblm import IBLMClassifier\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/content/irisdata_train.csv')\n",
    "df = pd.read_csv('../datasets/irisdata_train.csv')\n",
    "x_train = df.drop('target', axis=1)\n",
    "y_train = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {\n",
    "    'columns_name': True\n",
    "    }\n",
    "\n",
    "iblm = IBLMClassifier(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model creating.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'output_code' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#file_path = '/content/'\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../datasets/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43miblm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitanic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/iblm/iblmodel/iblm_classifier.py:100\u001b[0m, in \u001b[0;36mIBLMClassifier.fit\u001b[0;34m(self, x, y, model_name, file_path)\u001b[0m\n\u001b[1;32m     59\u001b[0m     col_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m))\n\u001b[1;32m     60\u001b[0m     col_option \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdf.columns = range(df.shape[1])\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     64\u001b[0m create_prompt \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[39mPlease create your code in compliance with all of the following conditions. Output should be code only. Do not enclose the output in ``python ``` or the like.\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[39m・Analyze the large amount of data below and create a \u001b[39m\u001b[39m{task_type_}\u001b[39;00m\u001b[39m code to accurately predict \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[39m------------------\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39m\u001b[39m\u001b[39m{dataset_str_}\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m------------------\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[39m・Each data type is as follows. If necessary, you can change the data type.\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39m------------------\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[39m\u001b[39m\u001b[39m{data_type_}\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m------------------\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[39m・Without using a machine learning model, we will create a code to predict a \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m based on logic from a large amount of input data.\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[39m・The column names, in order, are as follows \u001b[39m\u001b[39m{col_name_}\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39m・Please make your predictions as accurate as possible.\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[39m・Consider also computing \u001b[39m\u001b[39m{output_code_}\u001b[39;00m\u001b[39m when obtaining the final output.\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[39m・If \u001b[39m\u001b[39m{col_option_}\u001b[39;00m\u001b[39m is not blank, add it after \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdf = x.copy()\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[39m・You do not need to provide examples.\u001b[39m\n\u001b[1;32m     80\u001b[0m \u001b[39m・Create a code like the following. Do not change the code before \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfor index, row in df.iterrows():\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and after \u001b[39m\u001b[39m{output_code_}\u001b[39;00m\u001b[39m.\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[39m------------------\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[39mimport numpy as np\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef predict(x):\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[39m    df = x.copy()\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[39m    output = []\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[39m    for index, row in df.iterrows():\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[39m        # Please describe the process required to make the prediction below.\u001b[39m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[39m        \u001b[39m\u001b[39m{output_code_}\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[39m        output.append(y)\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[39m    return np.array(output)\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m     task_type_ \u001b[39m=\u001b[39m task_type,\n\u001b[1;32m     96\u001b[0m     dataset_str_ \u001b[39m=\u001b[39m dataset_str,\n\u001b[1;32m     97\u001b[0m     data_type_ \u001b[39m=\u001b[39m data_type,\n\u001b[1;32m     98\u001b[0m     col_name_ \u001b[39m=\u001b[39m col_name,\n\u001b[1;32m     99\u001b[0m     col_option_ \u001b[39m=\u001b[39m col_option,\n\u001b[0;32m--> 100\u001b[0m     output_code_ \u001b[39m=\u001b[39m output_code\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    103\u001b[0m \u001b[39m#print(create_prompt)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mwith\u001b[39;00m get_openai_callback() \u001b[39mas\u001b[39;00m cb:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'output_code' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#file_path = '/content/'\n",
    "file_path = '../datasets/'\n",
    "\n",
    "model = iblm.fit(x_train, y_train, model_name = 'titanic', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "def predict(x):\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Please describe the process required to make the prediction below.\n",
      "\n",
      "        # If the passenger is a female and in first or second class, predict survival\n",
      "        if row['sex'] == 'female' and (row['pclass'] == 1 or row['pclass'] == 2):\n",
      "            y = 1\n",
      "        # If the passenger is a child (age <= 15) and in first or second class, predict survival\n",
      "        elif row['age'] <= 15 and (row['pclass'] == 1 or row['pclass'] == 2):\n",
      "            y = 1\n",
      "        # If the passenger is a male and in third class, predict non-survival\n",
      "        elif row['sex'] == 'male' and row['pclass'] == 3:\n",
      "            y = 0\n",
      "        # If the passenger is an adult male and traveling alone, predict non-survival\n",
      "        elif row['adult_male'] and row['alone']:\n",
      "            y = 0\n",
      "        # For all other cases, predict non-survival\n",
      "        else:\n",
      "            y = 0\n",
      "\n",
      "        y = 1 / (1 + np.exp(-y))\n",
      "\n",
      "        output.append(y)\n",
      "    return np.array(output)\n"
     ]
    }
   ],
   "source": [
    "# Code of the model created\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/content/irisdata_test.csv')\n",
    "df = pd.read_csv('../datasets/irisdata_test.csv')\n",
    "x_test = df.drop('survived', axis=1)\n",
    "y_test = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = iblm.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)\n",
    "#y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8079877112135176\n",
      "Precision: 0.958904109589041\n",
      "Recall: 0.5405405405405406\n",
      "F1 score: 0.691358024691358\n",
      "ROC-AUC: 0.7626172090457806\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction from external files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_code import titanic\n",
    "\n",
    "y_proba = titanic.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Precision: 0.3956043956043956\n",
      "Recall: 1.0\n",
      "F1 score: 0.5669291338582677\n",
      "ROC-AUC: 0.9197048611111112\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 896\n",
      "\tPrompt Tokens: 341\n",
      "\tCompletion Tokens: 555\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04353\n"
     ]
    }
   ],
   "source": [
    "description = iblm.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- First, the function `predict` takes a DataFrame `x` as input and creates a copy of it named `df`. The columns of `df` are then renamed to be integer indices.\n",
      "\n",
      "- The function then initializes an empty list called `output` to store the predictions.\n",
      "\n",
      "- For each row in the DataFrame `df`, the function extracts the following features:\n",
      "  - `pclass`: Passenger class (First, Second, or Third)\n",
      "  - `sex`: Gender of the passenger (male or female)\n",
      "  - `age`: Age of the passenger\n",
      "  - `fare`: Ticket fare paid by the passenger\n",
      "  - `embarked`: Port of embarkation (C, Q, or S)\n",
      "  - `alone`: Whether the passenger is traveling alone or not (True or False)\n",
      "\n",
      "- The prediction logic is then applied to these features, and a variable `y` is initialized to 0.\n",
      "\n",
      "- The following conditions are checked and the corresponding values are added to `y`:\n",
      "  - If `pclass` is 'First', add 0.3 to `y`.\n",
      "  - If `pclass` is 'Second', add 0.15 to `y`.\n",
      "  - If `sex` is 'female', add 0.35 to `y`.\n",
      "  - If `age` is less than or equal to 16, add 0.1 to `y`.\n",
      "  - If `age` is greater than 16 and less than or equal to 32, add 0.05 to `y`.\n",
      "  - If `fare` is greater than 50, add 0.1 to `y`.\n",
      "  - If `embarked` is 'C', add 0.05 to `y`.\n",
      "  - If `alone` is True, add 0.05 to `y`.\n",
      "\n",
      "- After processing all the conditions, the value of `y` is transformed using the logistic function: `y = 1 / (1 + np.exp(-y))`. This transformation maps `y` to a value between 0 and 1, which can be interpreted as a probability.\n",
      "\n",
      "- The transformed value of `y` is then appended to the `output` list.\n",
      "\n",
      "- Once all rows in the DataFrame have been processed, the `output` list is converted to a NumPy array and returned by the function.\n",
      "\n",
      "Based on the whole process, we can say that the function `predict` takes a DataFrame containing passenger information and returns an array of probabilities representing the likelihood of each passenger meeting certain criteria (e.g., survival). The prediction is based on a simple rule-based model that considers passenger class, gender, age, fare, port of embarkation, and whether the passenger is traveling alone.\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
