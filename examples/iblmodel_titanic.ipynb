{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset\n",
    "* Get sample data [here](https://github.com/fuyu-quant/IBLM/tree/main/datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/IBLM/blob/main/examples/iblmodel_titanic.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/fuyu-quant/IBLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.13\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution('IBLM').version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from iblm import IBLMClassifier\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/content/titanicdata_train.csv')\n",
    "df = pd.read_csv('../datasets/titanicdata_train.csv')\n",
    "x_train = df.drop('survived', axis=1)\n",
    "y_train = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {\n",
    "    'columns_name': True\n",
    "    }\n",
    "\n",
    "iblm = IBLMClassifier(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model creating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d68efd9970911e599409d4ba50885ca4 in your message.).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 7782\n",
      "\tPrompt Tokens: 7557\n",
      "\tCompletion Tokens: 225\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24020999999999998\n"
     ]
    }
   ],
   "source": [
    "#file_path = '/content/'\n",
    "file_path = '../datasets/'\n",
    "\n",
    "model = iblm.fit(x_train, y_train, model_name = 'titanic', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "def predict(x):\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "\n",
      "        # Feature creation and data preprocessing\n",
      "        sex = 1 if row['sex'] == 'male' else 0\n",
      "        age = row['age']\n",
      "        pclass = row['pclass']\n",
      "        fare = row['fare']\n",
      "        sibsp = row['sibsp']\n",
      "        parch = row['parch']\n",
      "        adult_male = 1 if row['adult_male'] else 0\n",
      "        alone = 1 if row['alone'] else 0\n",
      "\n",
      "        # Prediction logic\n",
      "        y = -1.5 + 0.8 * sex - 0.02 * age - 0.5 * pclass + 0.001 * fare - 0.3 * sibsp - 0.2 * parch + 0.6 * adult_male - 0.4 * alone\n",
      "\n",
      "        y = 1 / (1 + np.exp(-y))\n",
      "        output.append(y)\n",
      "    return np.array(output)\n"
     ]
    }
   ],
   "source": [
    "# Code of the model created\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('/content/titanicdata_test.csv')\n",
    "df = pd.read_csv('../datasets/titanicdata_test.csv')\n",
    "x_test = df.drop('survived', axis=1)\n",
    "y_test = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05134269, 0.07094751, 0.06497929, 0.00929802, 0.1224426 ,\n",
       "              nan, 0.09500499, 0.04592424, 0.13359959, 0.104544  ,\n",
       "              nan,        nan, 0.11209679, 0.08069992, 0.06960486,\n",
       "       0.12025686, 0.01999207, 0.03339125, 0.14338616, 0.07914653,\n",
       "              nan, 0.01679829, 0.09854916, 0.07699459, 0.01477713,\n",
       "       0.01861944,        nan, 0.05149023, 0.06993613, 0.02474682,\n",
       "              nan, 0.0212772 , 0.11301074, 0.14185106,        nan,\n",
       "       0.09890062, 0.0362528 , 0.0837675 , 0.03892044, 0.04906188,\n",
       "              nan, 0.07585818, 0.02929801, 0.18089434,        nan,\n",
       "       0.02982754, 0.01348966,        nan, 0.02387229, 0.0150717 ,\n",
       "       0.03583802, 0.07228246, 0.09025708, 0.08533681,        nan,\n",
       "       0.06590662, 0.06975233, 0.08075712, 0.08891138, 0.02120158,\n",
       "       0.05514059, 0.06985487, 0.09911248, 0.02040918, 0.07783706,\n",
       "              nan, 0.07850965, 0.06988547,        nan, 0.04961947,\n",
       "              nan,        nan, 0.08471057,        nan,        nan,\n",
       "       0.1459345 ,        nan, 0.07370651, 0.12174589, 0.05006503,\n",
       "       0.05749508, 0.04320533, 0.02948343, 0.07228525, 0.08063503,\n",
       "       0.01960548, 0.03718342, 0.07135892, 0.05441658, 0.04048486,\n",
       "       0.08070919, 0.07363798, 0.02966568, 0.03195345,        nan,\n",
       "       0.04813715, 0.03865109, 0.02641637, 0.01631092, 0.07856392,\n",
       "              nan, 0.13221668, 0.19678076, 0.07571809,        nan,\n",
       "              nan, 0.19569834, 0.04370934, 0.05255294, 0.1341794 ,\n",
       "       0.09850031, 0.02883238, 0.11435587, 0.12057461, 0.09912365,\n",
       "       0.03334287, 0.02443501,        nan, 0.06042073, 0.05565406,\n",
       "       0.07938189,        nan, 0.04775353, 0.08454015,        nan,\n",
       "       0.0723929 , 0.07011006, 0.02540688,        nan,        nan,\n",
       "       0.03011658, 0.12430505, 0.01653593, 0.06339064,        nan,\n",
       "       0.06960648, 0.03153086,        nan,        nan, 0.0567487 ,\n",
       "       0.20676145, 0.09504763, 0.08533681, 0.21343103, 0.01568988,\n",
       "              nan, 0.02119121, 0.20940759, 0.08347918, 0.08531535,\n",
       "       0.04686547, 0.03216265, 0.06710244, 0.04983112,        nan,\n",
       "       0.14350237, 0.01673955, 0.02641637,        nan, 0.03812552,\n",
       "       0.13010847, 0.08224679, 0.05996957, 0.06619115, 0.02056672,\n",
       "       0.0807497 , 0.01777293, 0.08363137, 0.12460789, 0.03084799,\n",
       "       0.05885198, 0.07502468, 0.02388861, 0.0798674 , 0.02206744,\n",
       "       0.11314614, 0.04687552, 0.0961069 , 0.08224522,        nan,\n",
       "              nan,        nan, 0.05365665,        nan, 0.05355139,\n",
       "              nan, 0.0253945 , 0.03743484, 0.11036679, 0.02722943,\n",
       "              nan, 0.08224207, 0.0709541 , 0.01719825, 0.08018858,\n",
       "              nan, 0.03442303, 0.03718342,        nan, 0.06711026,\n",
       "       0.17748947,        nan, 0.02623693, 0.08843662, 0.13656711,\n",
       "       0.0541667 , 0.01230188, 0.0153488 , 0.06197765, 0.10817689,\n",
       "       0.02035727, 0.08389999, 0.0837675 , 0.03085845,        nan,\n",
       "       0.1682415 , 0.05018743, 0.16064322, 0.0202183 , 0.11820909,\n",
       "       0.07640327,        nan, 0.17189587, 0.14296293,        nan,\n",
       "       0.07095547, 0.09334582,        nan, 0.02004553,        nan,\n",
       "       0.12636921, 0.06464895, 0.1299388 , 0.07965821,        nan,\n",
       "       0.05992026,        nan, 0.10973508,        nan, 0.02197259,\n",
       "              nan, 0.06001116, 0.02120158, 0.03401955, 0.02124494,\n",
       "              nan, 0.11314614, 0.07777607, 0.08072929, 0.03813607,\n",
       "       0.01429989,        nan, 0.04779087, 0.00946717, 0.21266749,\n",
       "              nan, 0.05166144, 0.10618652, 0.06965831, 0.05395703,\n",
       "              nan, 0.0822056 , 0.11209679, 0.08545039, 0.08226598,\n",
       "              nan, 0.03551177,        nan, 0.04528444, 0.07782989,\n",
       "       0.08856064, 0.02162062,        nan, 0.01582189, 0.06701329,\n",
       "       0.24028822, 0.02836016,        nan, 0.07327245, 0.0784566 ,\n",
       "       0.07094586,        nan, 0.15528823, 0.03487121, 0.07780836,\n",
       "       0.12943324, 0.02739813,        nan, 0.02948343, 0.06710061,\n",
       "       0.05183318, 0.08075712,        nan, 0.0464409 ,        nan,\n",
       "       0.05720271, 0.02004553,        nan, 0.05885198, 0.08718507,\n",
       "       0.04679739,        nan, 0.08070765,        nan, 0.01813985,\n",
       "       0.04680855, 0.13314303, 0.05247209,        nan, 0.0578397 ,\n",
       "       0.04526067, 0.00858833, 0.00825436, 0.11774083, 0.14263498,\n",
       "       0.09500499, 0.04093396,        nan, 0.06068382, 0.08921562,\n",
       "       0.22633606, 0.11774083,        nan, 0.08070734, 0.0212021 ,\n",
       "       0.09854916, 0.03840521,        nan, 0.03915255, 0.01794034,\n",
       "              nan, 0.05775234, 0.11440651,        nan,        nan,\n",
       "       0.06562936, 0.08532477, 0.01263056,        nan, 0.06709801,\n",
       "       0.06125491, 0.02637728, 0.15530135,        nan, 0.09013809,\n",
       "       0.08584161, 0.02746483, 0.04634891,        nan, 0.06710244,\n",
       "       0.03017798, 0.0403446 , 0.07215822, 0.15711202,        nan,\n",
       "       0.06414286, 0.08128608, 0.09789813, 0.08076857,        nan,\n",
       "       0.0633951 , 0.03690755, 0.05055816,        nan, 0.10774352,\n",
       "       0.05754885,        nan, 0.04833763,        nan, 0.13906581,\n",
       "       0.02291012,        nan,        nan, 0.05355772, 0.15796475,\n",
       "       0.06885257, 0.06964831, 0.1810129 , 0.02663791, 0.0453672 ,\n",
       "       0.00637659,        nan,        nan,        nan, 0.06345004,\n",
       "       0.0262114 , 0.05921164, 0.02179796, 0.03419112, 0.11820909,\n",
       "       0.08124533, 0.15611204, 0.07696913, 0.0822512 , 0.08287579,\n",
       "       0.10086237, 0.06737997, 0.06053768, 0.07501397,        nan,\n",
       "       0.0710943 , 0.04684444, 0.16665804,        nan, 0.01151982,\n",
       "       0.03085845, 0.06710244, 0.10031315, 0.00832351,        nan,\n",
       "       0.08377358, 0.0567487 , 0.01322804,        nan, 0.02197259,\n",
       "       0.14389973, 0.08532477, 0.11061249,        nan, 0.02078642,\n",
       "              nan, 0.04578205, 0.08229492,        nan, 0.02290452,\n",
       "       0.10846666,        nan, 0.01591422, 0.12488085, 0.11438372,\n",
       "       0.1124107 , 0.05771585, 0.12848594, 0.06223953, 0.09178144,\n",
       "       0.09393568, 0.12057461,        nan, 0.05458061,        nan,\n",
       "       0.02273172, 0.18724679, 0.05267506, 0.10841832,        nan,\n",
       "       0.08688908, 0.07713328, 0.02297382, 0.00490248, 0.26743593,\n",
       "              nan, 0.18796757, 0.08387886, 0.01295671, 0.05946841,\n",
       "       0.09462557, 0.02103491, 0.08550249, 0.08689073, 0.09206629,\n",
       "       0.18800891, 0.03673554,        nan, 0.07636623, 0.10216015,\n",
       "       0.07402119, 0.05355772,        nan, 0.12248379, 0.05560087,\n",
       "       0.0807296 , 0.15792983, 0.02804373, 0.07640269, 0.0822512 ,\n",
       "       0.09500499, 0.02217208, 0.14019003, 0.06365835,        nan,\n",
       "       0.05569832,        nan, 0.14088002, 0.07106019, 0.07398692,\n",
       "       0.08530559, 0.05057136, 0.03138613,        nan, 0.06585201,\n",
       "       0.05803073, 0.09683071, 0.10275329, 0.07677457, 0.19990312,\n",
       "       0.08383565, 0.01836091,        nan, 0.13307957, 0.02205153,\n",
       "       0.05904128, 0.05725869,        nan, 0.12488085, 0.12488085,\n",
       "       0.07216492, 0.00795771, 0.23367577,        nan,        nan,\n",
       "              nan, 0.17636816, 0.04079188, 0.08596725, 0.06836533,\n",
       "       0.08098786, 0.08319176, 0.02968439, 0.22672446, 0.06835418,\n",
       "       0.04491622, 0.07533233, 0.0659582 , 0.07928481, 0.01638288,\n",
       "       0.09984931, 0.07227854, 0.13604911, 0.06464895, 0.04863752,\n",
       "              nan, 0.05663239, 0.08372562, 0.03557119, 0.09011554,\n",
       "       0.03761391,        nan, 0.01794651,        nan, 0.06712983,\n",
       "       0.07795229, 0.04963519, 0.0174725 ,        nan, 0.01146415,\n",
       "       0.0868871 ,        nan, 0.02966927,        nan, 0.0547505 ,\n",
       "       0.02526438, 0.07024056, 0.17508627,        nan, 0.07635389,\n",
       "       0.076368  , 0.02292122, 0.02341065, 0.05218199, 0.13695671,\n",
       "              nan, 0.14258301,        nan,        nan, 0.07641356,\n",
       "       0.09389313, 0.03376211, 0.01778741, 0.06960513, 0.01669434,\n",
       "       0.10275329, 0.02675928, 0.11920292, 0.0831816 , 0.07357519,\n",
       "       0.06835577, 0.14430313, 0.02292747, 0.09389313, 0.05181352,\n",
       "       0.0750134 , 0.05975711, 0.10069736, 0.00911457, 0.06901303,\n",
       "              nan, 0.02079405, 0.1012879 , 0.0544981 , 0.02479272,\n",
       "       0.03087341, 0.0736903 , 0.14679034, 0.02348737, 0.0265889 ,\n",
       "              nan,        nan, 0.11076056,        nan, 0.02765242,\n",
       "       0.02697378, 0.09994373,        nan, 0.07928177, 0.08693074,\n",
       "       0.03928475, 0.08231223,        nan, 0.07020764,        nan,\n",
       "       0.08377902, 0.14069857, 0.04884616, 0.06395029, 0.08856064,\n",
       "       0.05559562,        nan, 0.06344088, 0.13859605,        nan,\n",
       "       0.02086237, 0.03011293, 0.02497095, 0.07722943, 0.02523413,\n",
       "       0.02790494, 0.03786479, 0.11989235, 0.01694418,        nan,\n",
       "       0.04716041, 0.14081951, 0.03442068,        nan, 0.12271148,\n",
       "       0.02349941, 0.03468518, 0.17228708,        nan, 0.05902993,\n",
       "       0.07501397, 0.03269013, 0.16043433, 0.05064223, 0.03435662,\n",
       "       0.02429772, 0.08392658, 0.08532477,        nan, 0.0378026 ,\n",
       "       0.04015596, 0.06585944, 0.02125907, 0.11410291, 0.07635389,\n",
       "       0.00857005, 0.11639711, 0.06008665,        nan, 0.18392173,\n",
       "       0.06709149])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = iblm.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6036308623298033\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# ROC-AUC (you need prediction probabilities for this, not just class predictions)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Here we just reuse y_pred for simplicity\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_proba\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROC-AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:551\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    549\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    550\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 551\u001b[0m y_score \u001b[39m=\u001b[39m check_array(y_score, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    553\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    554\u001b[0m     y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m y_score\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y_score\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    555\u001b[0m ):\n\u001b[1;32m    556\u001b[0m     \u001b[39m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[1;32m    557\u001b[0m     \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m max_fpr \u001b[39m!=\u001b[39m \u001b[39m1.0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction from external files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_code import titanic\n",
    "\n",
    "y_proba = titanic.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Precision: 0.3956043956043956\n",
      "Recall: 1.0\n",
      "F1 score: 0.5669291338582677\n",
      "ROC-AUC: 0.9197048611111112\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 896\n",
      "\tPrompt Tokens: 341\n",
      "\tCompletion Tokens: 555\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04353\n"
     ]
    }
   ],
   "source": [
    "description = iblm.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- First, the function `predict` takes a DataFrame `x` as input and creates a copy of it named `df`. The columns of `df` are then renamed to be integer indices.\n",
      "\n",
      "- The function then initializes an empty list called `output` to store the predictions.\n",
      "\n",
      "- For each row in the DataFrame `df`, the function extracts the following features:\n",
      "  - `pclass`: Passenger class (First, Second, or Third)\n",
      "  - `sex`: Gender of the passenger (male or female)\n",
      "  - `age`: Age of the passenger\n",
      "  - `fare`: Ticket fare paid by the passenger\n",
      "  - `embarked`: Port of embarkation (C, Q, or S)\n",
      "  - `alone`: Whether the passenger is traveling alone or not (True or False)\n",
      "\n",
      "- The prediction logic is then applied to these features, and a variable `y` is initialized to 0.\n",
      "\n",
      "- The following conditions are checked and the corresponding values are added to `y`:\n",
      "  - If `pclass` is 'First', add 0.3 to `y`.\n",
      "  - If `pclass` is 'Second', add 0.15 to `y`.\n",
      "  - If `sex` is 'female', add 0.35 to `y`.\n",
      "  - If `age` is less than or equal to 16, add 0.1 to `y`.\n",
      "  - If `age` is greater than 16 and less than or equal to 32, add 0.05 to `y`.\n",
      "  - If `fare` is greater than 50, add 0.1 to `y`.\n",
      "  - If `embarked` is 'C', add 0.05 to `y`.\n",
      "  - If `alone` is True, add 0.05 to `y`.\n",
      "\n",
      "- After processing all the conditions, the value of `y` is transformed using the logistic function: `y = 1 / (1 + np.exp(-y))`. This transformation maps `y` to a value between 0 and 1, which can be interpreted as a probability.\n",
      "\n",
      "- The transformed value of `y` is then appended to the `output` list.\n",
      "\n",
      "- Once all rows in the DataFrame have been processed, the `output` list is converted to a NumPy array and returned by the function.\n",
      "\n",
      "Based on the whole process, we can say that the function `predict` takes a DataFrame containing passenger information and returns an array of probabilities representing the likelihood of each passenger meeting certain criteria (e.g., survival). The prediction is based on a simple rule-based model that considers passenger class, gender, age, fare, port of embarkation, and whether the passenger is traveling alone.\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
