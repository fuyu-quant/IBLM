{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install --upgrade iblm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iblm                         0.3.19\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list | grep iblm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from src.iblm.ibl import IBLModel\n",
    "from iblm import ibl\n",
    "\n",
    "from src.data import pseudodata\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 円形データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_data(n_points, num_train_data, radius, noise):\n",
    "    np.random.seed(0)\n",
    "    theta = np.random.uniform(0, 2*np.pi, n_points)\n",
    "    r = radius + np.random.normal(0, noise, n_points)  # ノイズを加える\n",
    "    x0 = r * np.cos(theta)\n",
    "    y0 = r * np.sin(theta)\n",
    "    labels0 = np.zeros(n_points)\n",
    "\n",
    "    # クラス1のデータ生成\n",
    "    theta = np.random.uniform(0, 2*np.pi, n_points)\n",
    "    r = radius * 0.5 + np.random.normal(0, noise, n_points)  # 内側の円で、ノイズを加える\n",
    "    x1 = r * np.cos(theta)\n",
    "    y1 = r * np.sin(theta)\n",
    "    labels1 = np.ones(n_points)\n",
    "\n",
    "    # データセットを結合\n",
    "    x = np.vstack((np.column_stack((x0, y0)), np.column_stack((x1, y1))))\n",
    "    y = np.hstack((labels0, labels1)).astype(int)\n",
    "\n",
    "    # データの順番をシャッフル\n",
    "    indices = np.random.permutation(len(y))\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    x = np.round(x, decimals=3)\n",
    "    x = pd.DataFrame(x)\n",
    "\n",
    "    x_train = x[0:num_train_data]\n",
    "    x_test = x[num_train_data:]\n",
    "\n",
    "    y_train = y[:num_train_data]\n",
    "    y_test = y[num_train_data:]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "radius=10\n",
    "noise=0.1\n",
    "\n",
    "x_train, x_test, y_train, y_test = circle_data(n_points=sample, num_train_data=num_train_data, radius=radius, noise=noise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVMデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_dataset(n_points, num_train_data):\n",
    "    np.random.seed(0)  # 再現性のためのシード設定\n",
    "\n",
    "    # クラス1とクラス2のデータ生成\n",
    "    x1_1 = np.random.normal(loc=0.5, scale=0.5, size=n_points)\n",
    "    x2_1 = np.random.normal(loc=0.5, scale=0.5, size=n_points)\n",
    "    y1 = np.ones(n_points)  # クラス1のラベル\n",
    "\n",
    "    x1_2 = np.random.normal(loc=-0.2, scale=0.5, size=n_points)\n",
    "    x2_2 = np.random.normal(loc=-0.2, scale=0.5, size=n_points)\n",
    "    y2 = np.zeros(n_points)  # クラス2のラベル\n",
    "\n",
    "    # データの結合\n",
    "    x1 = np.concatenate([x1_1, x1_2])\n",
    "    x2 = np.concatenate([x2_1, x2_2])\n",
    "    x = np.vstack([x1, x2]).T\n",
    "    y = np.concatenate([y1, y2])\n",
    "\n",
    "    # データのシャッフル\n",
    "    indices = np.random.permutation(n_points * 2)\n",
    "    x_shuffled = x[indices]\n",
    "    y_shuffled = y[indices]\n",
    "\n",
    "    # pandas DataFrameへの変換\n",
    "    x_shuffled = pd.DataFrame(x_shuffled)\n",
    "\n",
    "    # トレーニングセットとテストセットに分割\n",
    "    x_train = x_shuffled.iloc[:num_train_data]\n",
    "    x_test = x_shuffled.iloc[num_train_data:]\n",
    "    y_train = y_shuffled[:num_train_data]\n",
    "    y_test = y_shuffled[num_train_data:]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = svm_dataset(n_points = sample, num_train_data = num_train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDTデータセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_dataset(n_points, num_train_data):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Generate a mix of sine and cosine functions with noise as features\n",
    "    X1 = np.linspace(0, 6*np.pi, n_points)\n",
    "    X2 = np.sin(X1) + np.random.normal(0, 0.1, n_points)\n",
    "    X3 = np.cos(X1) + np.random.normal(0, 0.1, n_points)\n",
    "    X4 = X2 * X3 + np.random.normal(0, 0.1, n_points)  # Interaction term\n",
    "    x = np.vstack((X2, X3, X4)).T\n",
    "\n",
    "    # Generate labels based on a non-linear combination of features\n",
    "    y = (np.sin(X1) > 0).astype(int)\n",
    "\n",
    "    # Fix: Corrected the way of shuffling data using a single sequence of indices\n",
    "    indices = np.arange(n_points)  # Fixed to generate indices for the actual number of points\n",
    "    np.random.shuffle(indices)\n",
    "    x_shuffled = x[indices]\n",
    "    y_shuffled = y[indices]\n",
    "\n",
    "    # Conversion to pandas DataFrame\n",
    "    x_shuffled = pd.DataFrame(x_shuffled, columns=['Feature1', 'Feature2', 'Feature3'])\n",
    "\n",
    "    # Splitting into training and test sets\n",
    "    x_train = x_shuffled.iloc[:num_train_data]\n",
    "    x_test = x_shuffled.iloc[num_train_data:]\n",
    "    y_train = y_shuffled[:num_train_data]\n",
    "    y_test = y_shuffled[num_train_data:]\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = lgbm_dataset(n_points = sample, num_train_data = num_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn擬似データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = 550 # 50〜300\n",
    "num_test_data = 1000\n",
    "sample = num_train_data + num_test_data\n",
    "n_informative = 2\n",
    "n_redundant = 0\n",
    "n_features = n_informative + n_redundant\n",
    "weights = [0.5, 0.5]\n",
    "flip_y=0\n",
    "seed = 3655  # 3655,3656,3657\n",
    "\n",
    "# testデータの個数を揃えるためにtrain_test_splitを使っていない\n",
    "x, y = make_classification(\n",
    "    n_samples = sample,  # データ数\n",
    "    n_features = n_features,  # 特徴量の数\n",
    "    n_informative = n_informative,  # ラベル予測に意味のある特徴量の数\n",
    "    n_redundant = n_redundant,  # 冗長な特徴量\n",
    "    weights = weights,  # [0,1]の割合\n",
    "    flip_y = flip_y, # 逆のラベルに反転する割合\n",
    "    random_state = seed\n",
    "    )\n",
    "\n",
    "x = np.round(x, decimals=3)\n",
    "x = pd.DataFrame(x)\n",
    "\n",
    "x_test = x[0:num_test_data]\n",
    "x_train = x[num_test_data:]\n",
    "\n",
    "y_test = y[:num_test_data]\n",
    "y_train = y[num_test_data:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 06:09:33,452 [iblm.ibl][INFO] (ibl:ibl.py:fit:154)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8765423948530824,\n",
       " 'pr_auc': 0.9027114479229366,\n",
       " 'accuracy': 0.665,\n",
       " 'recall': 0.3464566929133858,\n",
       " 'precision': 0.9832402234636871,\n",
       " 'f1_score': 0.512372634643377}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iblm = ibl.IBLModel(api_type=\"openai\", model_name=\"gpt-4-0125-preview\", objective=\"binary\")\n",
    "model = iblm.fit(x_train, y_train, seed=3655)\n",
    "y_pred = iblm.predict(x_test)\n",
    "iblm.evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 06:07:48,926 [iblm.ibl][INFO] (ibl:ibl.py:fit:154)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.24206596888803533,\n",
       " 'pr_auc': 0.36019643762895803,\n",
       " 'accuracy': 0.317,\n",
       " 'recall': 0.3333333333333333,\n",
       " 'precision': 0.3159922928709056,\n",
       " 'f1_score': 0.32443125618199803}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iblm = ibl.IBLModel(api_type=\"openai\", model_name=\"gpt-3.5-turbo-0125\", objective=\"binary\")\n",
    "model = iblm.fit(x_train, y_train, seed=3655)\n",
    "y_pred = iblm.predict(x_test)\n",
    "iblm.evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 06:07:54,949 [iblm.ibl][INFO] (ibl:ibl.py:fit:154)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.8450683374943985,\n",
       " 'pr_auc': 0.7985771976596885,\n",
       " 'accuracy': 0.749,\n",
       " 'recall': 0.7601626016260162,\n",
       " 'precision': 0.73767258382643,\n",
       " 'f1_score': 0.7487487487487487}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iblm = ibl.IBLModel(api_type=\"gemini\", model_name=\"gemini-pro\", objective=\"binary\")\n",
    "model = iblm.fit(x_train, y_train)\n",
    "y_pred = iblm.predict(x_test)\n",
    "iblm.evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ロジスティック回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUC: 0.9724\n",
      "Logistic Regression Accuracy: 0.9360\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=3655)\n",
    "log_reg.fit(x_train, y_train)\n",
    "log_reg_probs = log_reg.predict_proba(x_test)[:, 1]\n",
    "log_reg_auc = roc_auc_score(y_test, log_reg_probs)\n",
    "\n",
    "\n",
    "log_reg_preds = log_reg.predict(x_test) # 予測ラベルを計算\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_preds) # 精度を計算\n",
    "\n",
    "# AUCと精度を出力\n",
    "print(f\"Logistic Regression AUC: {log_reg_auc:.4f}\")\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM AUC: 0.9807\n",
      "SVM Accuracy: 0.9360\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(probability=True, random_state=42)  # probability=Trueで確率出力を有効化\n",
    "svm.fit(x_train, y_train)\n",
    "svm_probs = svm.predict_proba(x_test)[:, 1]\n",
    "svm_auc = roc_auc_score(y_test, svm_probs)\n",
    "\n",
    "# 追加コード: 精度を計算\n",
    "svm_preds = svm.predict(x_test) # 予測ラベルを計算\n",
    "svm_accuracy = accuracy_score(y_test, svm_preds) # 精度を計算\n",
    "\n",
    "# AUCと精度を出力\n",
    "print(f\"SVM AUC: {svm_auc:.4f}\")\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT AUC: 0.9814\n",
      "GBDT Accuracy: 0.9240\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_clf.fit(x_train, y_train)\n",
    "y_pred = gb_clf.predict_proba(x_test)[:, 1]\n",
    "gbdt_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# 追加コード: 精度を計算\n",
    "gb_clf_preds = gb_clf.predict(x_test) # 予測ラベルを計算\n",
    "gb_clf_accuracy = accuracy_score(y_test, gb_clf_preds) # 精度を計算\n",
    "\n",
    "# AUCと精度を出力\n",
    "print(f\"GBDT AUC: {gbdt_auc:.4f}\")\n",
    "print(f\"GBDT Accuracy: {gb_clf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948585"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.99180+ 0.93893 + 0.92402 + 0.93959)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
