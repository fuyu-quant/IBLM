{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install iblm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/fuyu-quant/IBLM.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.1\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution('IBLM').version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from iblm import IBLMClassifier\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "\n",
    "df = pd.read_csv(f'../data/text/text_{n}_train.csv')\n",
    "x_train = df.drop('Target', axis=1)\n",
    "y_train = df['Target']\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It breaks my heart that this movie is not appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Murder investigation goes on back stage whil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BEFORE THE DEVIL KNOWS YOU'RE DEAD starts off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You'd think you're in for some serious sightse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I saw his movie in Dallas, Texas when it came ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This documentary on schlockmeister William Cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How I got into it: When I started watching thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This was a very good film. I didn't go into it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The movie took a new angle to Gandhi's life, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ok, so it may not be the award-winning \"movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Our Song is a marvelous example of passionate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I lived in Tokyo for 7 months. Knowing the rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When a man who doesn't have Alzheimer's can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This is by far the worst adaptation of Jane Ey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lee hosted the 100 Years of Horror for Ted New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Somewhere, on this site, someone wrote that to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>This movie makes a promising start and then ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Watching \"Der himmel über Berlin\" as a teen in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I have to admit that i liked the first half of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wow. This is really not that good. &lt;br /&gt;&lt;br /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Usually, I don't think Hollywood productions a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This movie is just truly awful, the eye-candy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I cannot vote on this because I wouldn't watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The original is a relaxing watch, with some tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   It breaks my heart that this movie is not appr...\n",
       "1   A Murder investigation goes on back stage whil...\n",
       "2   BEFORE THE DEVIL KNOWS YOU'RE DEAD starts off ...\n",
       "3   You'd think you're in for some serious sightse...\n",
       "4   I saw his movie in Dallas, Texas when it came ...\n",
       "5   This documentary on schlockmeister William Cas...\n",
       "6   How I got into it: When I started watching thi...\n",
       "7   This was a very good film. I didn't go into it...\n",
       "8   The movie took a new angle to Gandhi's life, w...\n",
       "9   Ok, so it may not be the award-winning \"movie ...\n",
       "10  Our Song is a marvelous example of passionate,...\n",
       "11  I lived in Tokyo for 7 months. Knowing the rea...\n",
       "12  When a man who doesn't have Alzheimer's can't ...\n",
       "13  This is by far the worst adaptation of Jane Ey...\n",
       "14  Lee hosted the 100 Years of Horror for Ted New...\n",
       "15  Somewhere, on this site, someone wrote that to...\n",
       "16  This movie makes a promising start and then ge...\n",
       "17  Watching \"Der himmel über Berlin\" as a teen in...\n",
       "18  I have to admit that i liked the first half of...\n",
       "19  Wow. This is really not that good. <br /><br /...\n",
       "20  Usually, I don't think Hollywood productions a...\n",
       "21  This movie is just truly awful, the eye-candy ...\n",
       "22  I cannot vote on this because I wouldn't watch...\n",
       "23  The original is a relaxing watch, with some tr..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {'columns_name': True}\n",
    "\n",
    "iblm = IBLMClassifier(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:24\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n"
     ]
    }
   ],
   "source": [
    "file_path = '../models/text/'\n",
    "\n",
    "print(f'Number of data:{len(x_train)}')\n",
    "model = iblm.fit(x_train, y_train, model_name = 'text', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "def predict(x):\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "\n",
      "        # Count the number of positive and negative words in the text\n",
      "        positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'love', 'best', 'favorite', 'enjoy', 'beautiful']\n",
      "        negative_words = ['bad', 'terrible', 'awful', 'horrible', 'worst', 'hate', 'dislike', 'boring', 'ugly', 'disappointing']\n",
      "\n",
      "        positive_count = sum([1 for word in positive_words if word in row['text'].lower()])\n",
      "        negative_count = sum([1 for word in negative_words if word in row['text'].lower()])\n",
      "\n",
      "        # Calculate the probability of the target being 1 based on the counts of positive and negative words\n",
      "        total_count = positive_count + negative_count\n",
      "        if total_count == 0:\n",
      "            y = 0.5\n",
      "        else:\n",
      "            y = positive_count / total_count\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n"
     ]
    }
   ],
   "source": [
    "# Code of the model created\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../data/text/text_{n}_test.csv')\n",
    "x_test = df.drop('Target', axis=1)\n",
    "y_test = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = iblm.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7174487508007688\n",
      "Precision: 0.6831456127335267\n",
      "Recall: 0.8110986547085202\n",
      "F1 score: 0.7416437854658613\n",
      "ROC-AUC: 0.7683282998443399\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create multiple code models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model creating.\n",
      "Tokens Used: 7314\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 281\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22785\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7308\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 275\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22748999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7276\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 243\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22557\n",
      "> Start of model creating.\n",
      "Tokens Used: 7299\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 266\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22694999999999999\n",
      "> Start of model creating.\n",
      "Tokens Used: 7303\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 270\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22718999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7295\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 262\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22670999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7413\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 380\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23379\n",
      "> Start of model creating.\n",
      "Tokens Used: 7295\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 262\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22670999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7288\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 255\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22629\n",
      "> Start of model creating.\n",
      "Tokens Used: 7314\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 281\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22785\n",
      "> Start of model creating.\n",
      "Tokens Used: 7309\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 276\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22754999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7298\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 265\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22688999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7308\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 275\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22748999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7308\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 275\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22748999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7287\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 254\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22623\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7287\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 254\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22623\n",
      "> Start of model creating.\n",
      "Tokens Used: 7297\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 264\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22682999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7314\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 281\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22785\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7286\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 253\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22616999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7320\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 287\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22820999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7283\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 250\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22598999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7307\n",
      "\tPrompt Tokens: 7033\n",
      "\tCompletion Tokens: 274\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22742999999999997\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "\n",
    "df = pd.read_csv(f'../data/text/text_{n}_train.csv')\n",
    "x_train = df.drop('Target', axis=1)\n",
    "y_train = df['Target']\n",
    "\n",
    "file_path = '../models/text/'\n",
    "for i in range(1,31):\n",
    "    model = iblm.fit(x_train, y_train, model_name = f'text_{i}', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('iblm-L6oop2Mj-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67008fb9323ab6c1c90f5d9822582dbef34eff0db475eec3af4e0e9456757ebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
