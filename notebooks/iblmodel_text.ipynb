{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/fuyu-quant/IBLM.git@feature-in-context-learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.39\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution('IBLM').version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from iblm import IBLMClassifier\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "\n",
    "df = pd.read_csv(f'../data/text/text_{n}_train.csv')\n",
    "x_train = df.drop('Target', axis=1)\n",
    "y_train = df['Target']\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It breaks my heart that this movie is not appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Murder investigation goes on back stage whil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BEFORE THE DEVIL KNOWS YOU'RE DEAD starts off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You'd think you're in for some serious sightse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I saw his movie in Dallas, Texas when it came ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This documentary on schlockmeister William Cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How I got into it: When I started watching thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This was a very good film. I didn't go into it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The movie took a new angle to Gandhi's life, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ok, so it may not be the award-winning \"movie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Our Song is a marvelous example of passionate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I lived in Tokyo for 7 months. Knowing the rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When a man who doesn't have Alzheimer's can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This is by far the worst adaptation of Jane Ey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lee hosted the 100 Years of Horror for Ted New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Somewhere, on this site, someone wrote that to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>This movie makes a promising start and then ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Watching \"Der himmel über Berlin\" as a teen in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I have to admit that i liked the first half of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wow. This is really not that good. &lt;br /&gt;&lt;br /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Usually, I don't think Hollywood productions a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This movie is just truly awful, the eye-candy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I cannot vote on this because I wouldn't watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The original is a relaxing watch, with some tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   It breaks my heart that this movie is not appr...\n",
       "1   A Murder investigation goes on back stage whil...\n",
       "2   BEFORE THE DEVIL KNOWS YOU'RE DEAD starts off ...\n",
       "3   You'd think you're in for some serious sightse...\n",
       "4   I saw his movie in Dallas, Texas when it came ...\n",
       "5   This documentary on schlockmeister William Cas...\n",
       "6   How I got into it: When I started watching thi...\n",
       "7   This was a very good film. I didn't go into it...\n",
       "8   The movie took a new angle to Gandhi's life, w...\n",
       "9   Ok, so it may not be the award-winning \"movie ...\n",
       "10  Our Song is a marvelous example of passionate,...\n",
       "11  I lived in Tokyo for 7 months. Knowing the rea...\n",
       "12  When a man who doesn't have Alzheimer's can't ...\n",
       "13  This is by far the worst adaptation of Jane Ey...\n",
       "14  Lee hosted the 100 Years of Horror for Ted New...\n",
       "15  Somewhere, on this site, someone wrote that to...\n",
       "16  This movie makes a promising start and then ge...\n",
       "17  Watching \"Der himmel über Berlin\" as a teen in...\n",
       "18  I have to admit that i liked the first half of...\n",
       "19  Wow. This is really not that good. <br /><br /...\n",
       "20  Usually, I don't think Hollywood productions a...\n",
       "21  This movie is just truly awful, the eye-candy ...\n",
       "22  I cannot vote on this because I wouldn't watch...\n",
       "23  The original is a relaxing watch, with some tr..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = OpenAI(temperature=0, model_name = 'gpt-4-0613')\n",
    "\n",
    "params = {'columns_name': True}\n",
    "\n",
    "iblm = IBLMClassifier(llm_model = llm_model, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:24\n",
      "Tokens Used: 7355\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 268\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22869\n"
     ]
    }
   ],
   "source": [
    "file_path = '../models/text/'\n",
    "\n",
    "print(f'Number of data:{len(x_train)}')\n",
    "model = iblm.fit(x_train, y_train, model_name = 'text', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import re\n",
      "\n",
      "def predict(x):\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "\n",
      "        text = row['text']\n",
      "        positive_words = ['excellent', 'amazing', 'great', 'wonderful', 'best', 'love', 'good', 'favorite', 'enjoy', 'beautiful']\n",
      "        negative_words = ['awful', 'terrible', 'worst', 'boring', 'disappointing', 'bad', 'hate', 'annoying', 'waste', 'ridiculous']\n",
      "\n",
      "        positive_count = sum([1 for word in positive_words if word in text.lower()])\n",
      "        negative_count = sum([1 for word in negative_words if word in text.lower()])\n",
      "\n",
      "        # Calculate the sentiment score\n",
      "        sentiment_score = (positive_count - negative_count) / (positive_count + negative_count + 1)\n",
      "\n",
      "        # Normalize the sentiment score to a probability value between 0 and 1\n",
      "        y = (sentiment_score + 1) / 2\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n"
     ]
    }
   ],
   "source": [
    "# Code of the model created\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../data/text/text_{n}_test.csv')\n",
    "x_test = df.drop('Target', axis=1)\n",
    "y_test = df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = iblm.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7326233183856502\n",
      "Precision: 0.7028914652884481\n",
      "Recall: 0.8058936579115952\n",
      "F1 score: 0.7508766694023727\n",
      "ROC-AUC: 0.8108176450289137\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create multiple code models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 7352\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 265\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22851\n",
      "Tokens Used: 7448\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 361\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23426999999999998\n",
      "Tokens Used: 7456\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 369\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23475\n",
      "Tokens Used: 7332\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 245\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22730999999999998\n",
      "Tokens Used: 7353\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 266\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22857\n",
      "Tokens Used: 7354\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 267\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22863\n",
      "Tokens Used: 7424\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 337\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23282999999999998\n",
      "Tokens Used: 7399\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 312\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23132999999999998\n",
      "Tokens Used: 7463\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 376\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23517\n",
      "Tokens Used: 7368\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 281\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22947\n",
      "Tokens Used: 7455\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 368\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23468999999999998\n",
      "Tokens Used: 7318\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 231\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22647\n",
      "Tokens Used: 7442\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 355\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23391\n",
      "Tokens Used: 7354\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 267\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22863\n",
      "Tokens Used: 7354\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 267\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22863\n",
      "Tokens Used: 7347\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 260\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22821\n",
      "Tokens Used: 7448\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 361\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23426999999999998\n",
      "Tokens Used: 7320\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 233\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22658999999999999\n",
      "Tokens Used: 7433\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 346\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23337\n",
      "Tokens Used: 7336\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 249\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22755\n",
      "Tokens Used: 7352\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 265\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22851\n",
      "Tokens Used: 7363\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 276\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22916999999999998\n",
      "Tokens Used: 7438\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 351\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23367\n",
      "Tokens Used: 7349\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 262\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22832999999999998\n",
      "Tokens Used: 7397\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 310\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23121\n",
      "Tokens Used: 7352\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 265\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22851\n",
      "Tokens Used: 7662\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 575\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24711\n",
      "Tokens Used: 8192\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 1105\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.27891\n",
      "Tokens Used: 7331\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 244\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22724999999999998\n",
      "Tokens Used: 7349\n",
      "\tPrompt Tokens: 7087\n",
      "\tCompletion Tokens: 262\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.22832999999999998\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "\n",
    "df = pd.read_csv(f'../data/text/text_{n}_train.csv')\n",
    "x_train = df.drop('Target', axis=1)\n",
    "y_train = df['Target']\n",
    "\n",
    "file_path = '../models/text/'\n",
    "for i in range(1,31):\n",
    "    model = iblm.fit(x_train, y_train, model_name = f'text_{i}', file_path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run error\n",
      "run error\n",
      "run error\n",
      "3\n",
      "[4, 7, 10]\n",
      "[0.7471205861791317, 0.7381230087225826, 0.8075368240762895, 0.8127997913230525, 0.8156461272648776, 0.7993254946914317, 0.7964840353081047, 0.8080917257761557, 0.8041486707444143, 0.6774667357793527, 0.8047020655524371, 0.8156461272648776, 0.7781046229748911, 0.7381230087225826, 0.7748509837862029, 0.8251222903647978, 0.8085187564815587, 0.7471205861791317, 0.8047020655524371, 0.8127418529347432, 0.7941379586029751, 0.7983026966618254, 0.7471205861791317, 0.8465177371044941, 0.7983026966618254, 0.7943009337650883, 0.8015443897249623]\n",
      "Average Value: 0.7887630503103465\n",
      "Maximum Value: 0.8465177371044941\n",
      "Minimum Value: 0.6774667357793527\n"
     ]
    }
   ],
   "source": [
    "n = 25\n",
    "\n",
    "df = pd.read_csv(f'../data/text/text_{n}_test.csv')\n",
    "x_test = df.drop('Target', axis=1)\n",
    "y_test = df['Target']\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "error_count = 0\n",
    "error_list = []\n",
    "auc_list = []\n",
    "\n",
    "\n",
    "for i in range(1,31):\n",
    "\n",
    "    import_file = f'import models.text.text_{i} as codemodel'\n",
    "\n",
    "    exec(import_file)\n",
    "\n",
    "    try:\n",
    "        y_proba = codemodel.predict(x_test)\n",
    "        y_pred = (y_proba > 0.5).astype(int)\n",
    "        negative_values_exist = np.any(y_proba < 0)\n",
    "        values_greater_than_one_exist = np.any(y_proba > 1)\n",
    "        if negative_values_exist:\n",
    "            error_list.append(i)\n",
    "            error_count += 1\n",
    "            print(f\"Negative values exist：{negative_values_exist}\")\n",
    "\n",
    "        elif values_greater_than_one_exist:\n",
    "            error_list.append(i)\n",
    "            error_count += 1\n",
    "            print(f\"Positive values exist：{values_greater_than_one_exist}\")\n",
    "\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            auc_list.append(roc_auc)\n",
    "        \n",
    "    except Exception:\n",
    "        print('run error')\n",
    "        error_count += 1\n",
    "        error_list.append(i)\n",
    "        pass\n",
    "\n",
    "print(error_count)\n",
    "print(error_list)\n",
    "print(auc_list)\n",
    "average = sum(auc_list) / len(auc_list)\n",
    "print(\"Average Value:\", average)\n",
    "max_value = max(auc_list)\n",
    "min_value = min(auc_list)\n",
    "print(\"Maximum Value:\", max_value)\n",
    "print(\"Minimum Value:\", min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('iblm-L6oop2Mj-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67008fb9323ab6c1c90f5d9822582dbef34eff0db475eec3af4e0e9456757ebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
