{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class Classifier():\n",
    "    def __init__(\n",
    "        self, \n",
    "        llm_model_name, \n",
    "        params\n",
    "        ):\n",
    "        self.llm_model_name = llm_model_name\n",
    "        self.llm_model = OpenAI(temperature=0, model_name = self.llm_model_name)\n",
    "\n",
    "        #self.llm_model = llm_model,\n",
    "        self.columns_name = params['columns_name']\n",
    "\n",
    "        self.model_code = None\n",
    "\n",
    "    def fit(self, x, y, model_name, file_path=None):\n",
    "        print(\"> Start of model creating.\")\n",
    "        df = x.copy()\n",
    "\n",
    "        df['target'] = y\n",
    "\n",
    "        # Determine whether binary or multivalued classification is used\n",
    "        if len(df['target'].unique()) == 2:\n",
    "            task_type = 'binary classification'\n",
    "            output_code = 'y = 1 / (1 + np.exp(-y))'\n",
    "        else:\n",
    "            task_type = 'multi-class classification'\n",
    "\n",
    "        # Obtaining data types\n",
    "        data_type = ', '.join(df.dtypes.astype(str))\n",
    "\n",
    "\n",
    "\n",
    "        # Create a string dataset\n",
    "        dataset = []\n",
    "        for index, row in df.iterrows():\n",
    "            row_as_str = [str(item) for item in row.tolist()] \n",
    "            dataset.append(','.join(row_as_str))\n",
    "        dataset_str = '\\n'.join(dataset)\n",
    "\n",
    "\n",
    "        # column name\n",
    "        if self.columns_name:\n",
    "            col_name = ', '.join(df.columns.astype(str))\n",
    "            col_option = ''\n",
    "\n",
    "        else:\n",
    "            # serial number\n",
    "            df.columns = range(df.shape[1])\n",
    "            col_name = ', '.join(df.columns.astype(str))\n",
    "            col_option = 'df.columns = range(df.shape[1])'\n",
    "\n",
    "\n",
    "\n",
    "        create_prompt = \"\"\"\n",
    "        Please create your code in compliance with all of the following conditions. Output should be code only. Do not enclose the output in ``python ``` or the like.\n",
    "        ・Analyze the large amount of data below and create a {task_type_} code to accurately predict \"target\".\n",
    "        ------------------\n",
    "        {dataset_str_}\n",
    "        ------------------\n",
    "        ・Each data type is as follows. If necessary, you can change the data type.\n",
    "        ・Create code that can make predictions about new data based on logic from large amounts of input data without using machine learning models.\n",
    "        ・If input is available, the column names below should also be used to help make decisions when creating the predictive model. Column Name:{col_name_}\n",
    "        ・Create a code like the following. Do not change the input or output format.\n",
    "        ・If {col_option_} is not blank, add it after 'df = x.copy()'.\n",
    "        ・You do not need to provide examples.\n",
    "        ------------------\n",
    "        import numpy as np\n",
    "\n",
    "        def predict(x):\n",
    "            df = x.copy()\n",
    "\n",
    "            output = []\n",
    "            for index, row in df.iterrows():\n",
    "\n",
    "\n",
    "                # Feature creation and data preprocessing\n",
    "\n",
    "\n",
    "                {output_code_}\n",
    "                output.append(y)\n",
    "\n",
    "            output = np.array(output)\n",
    "                \n",
    "            return output\n",
    "        \"\"\".format(\n",
    "            task_type_ = task_type,\n",
    "            dataset_str_ = dataset_str,\n",
    "            model_name_ = model_name,\n",
    "            col_name_ = col_name,\n",
    "            col_option_ = col_option,\n",
    "            output_code_ = output_code\n",
    "            )\n",
    "\n",
    "        #print(create_prompt)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            model_code = self.llm_model(create_prompt)\n",
    "            print(cb)\n",
    "\n",
    "\n",
    "        # Save to File\n",
    "        if file_path != None:\n",
    "            with open(file_path + f'{model_name}.py', mode='w') as file:\n",
    "                file.write(model_code)\n",
    "\n",
    "\n",
    "        self.model_code = model_code\n",
    "\n",
    "        return model_code\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.model_code is None:\n",
    "            raise Exception(\"You must train the model before predicting!\")\n",
    "\n",
    "        code = self.model_code\n",
    "\n",
    "        # = re.search(r'def (\\w+)', function_string).group(1)\n",
    "        #code = self.model_code + '\\n'# + f'model = model({x})'\n",
    "        exec(code, globals())\n",
    "\n",
    "        #model = namespace[\"code\"]\n",
    "        \n",
    "        y = predict(x)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def interpret(self):\n",
    "        if self.model_code is None:\n",
    "            raise Exception(\"You must train the model before interpreting!\")\n",
    "\n",
    "        interpret_prompt = \"\"\"\n",
    "        Refer to the code below and explain how you are going to process the data and make predictions.\n",
    "        The only part to explain is the part where the data is processed.\n",
    "        Do not explain df = x.copy().\n",
    "        Please output the data in bulleted form.\n",
    "        Please tell us what you can say based on the whole process.\n",
    "        ------------------\n",
    "        {model_code_}\n",
    "        \"\"\".format(\n",
    "            model_code_ = self.model_code\n",
    "        )\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            output = self.llm_model(interpret_prompt)\n",
    "            print(cb)\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/learning.csv')\n",
    "x_train = df.drop('survived', axis=1)\n",
    "y_train = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {'columns_name': False}\n",
    "\n",
    "ibl = Classifier(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model creating.\n",
      "Tokens Used: 3698\n",
      "\tPrompt Tokens: 3436\n",
      "\tCompletion Tokens: 262\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.1188\n"
     ]
    }
   ],
   "source": [
    "model = ibl.fit(x_train, y_train, model_name = 'titanic', file_path='./model_code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "def predict(x):\n",
      "    df = x.copy()\n",
      "    df.columns = range(df.shape[1])\n",
      "\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "\n",
      "        # Feature creation and data preprocessing\n",
      "        pclass = row[7]\n",
      "        sex = row[1]\n",
      "        age = row[2]\n",
      "        fare = row[5]\n",
      "        embarked = row[6]\n",
      "        alone = row[13]\n",
      "\n",
      "        # Prediction logic\n",
      "        y = 0\n",
      "\n",
      "        if pclass == 'First':\n",
      "            y += 0.3\n",
      "        elif pclass == 'Second':\n",
      "            y += 0.1\n",
      "\n",
      "        if sex == 'female':\n",
      "            y += 0.35\n",
      "\n",
      "        if age <= 16:\n",
      "            y += 0.2\n",
      "        elif age > 16 and age <= 32:\n",
      "            y += 0.1\n",
      "\n",
      "        if fare > 50:\n",
      "            y += 0.1\n",
      "\n",
      "        if embarked == 'C':\n",
      "            y += 0.1\n",
      "\n",
      "        if alone == 'True':\n",
      "            y -= 0.1\n",
      "\n",
      "        y = 1 / (1 + np.exp(-y))\n",
      "        output.append(y)\n",
      "\n",
      "    output = np.array(output)\n",
      "\n",
      "    return output\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/pred.csv')\n",
    "x_test = df.drop('survived', axis=1)\n",
    "y_test = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = ibl.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "Precision: 0.43902439024390244\n",
      "Recall: 1.0\n",
      "F1 score: 0.6101694915254238\n",
      "ROC-AUC: 0.9097222222222222\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction from external files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import titanic\n",
    "\n",
    "y_proba = titanic.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "Precision: 0.7435897435897436\n",
      "Recall: 0.8055555555555556\n",
      "F1 score: 0.7733333333333334\n",
      "ROC-AUC: 0.9266493055555556\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 881\n",
      "\tPrompt Tokens: 537\n",
      "\tCompletion Tokens: 344\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.036750000000000005\n"
     ]
    }
   ],
   "source": [
    "description = ibl.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data preprocessing:\n",
      "    - Fill missing 'age' values with the median age.\n",
      "    - Fill missing 'fare' values with the median fare.\n",
      "    - Fill missing 'embarked' values with the mode (most frequent) of the 'embarked' column.\n",
      "\n",
      "- Feature creation:\n",
      "    - Create a new binary feature 'is_female' based on the 'sex' column.\n",
      "    - Create a new binary feature 'is_child' based on the 'age' column.\n",
      "    - Create a new binary feature 'is_adult_male' based on the 'adult_male' column.\n",
      "    - Create a new binary feature 'is_alone' based on the 'alone' column.\n",
      "    - Create new binary features 'is_first_class', 'is_second_class', and 'is_third_class' based on the 'pclass' column.\n",
      "    - Create new binary features 'embarked_C', 'embarked_Q', and 'embarked_S' based on the 'embarked' column.\n",
      "\n",
      "- Prediction logic:\n",
      "    - Initialize a variable 'y' to 0.\n",
      "    - Add or subtract weights to 'y' based on the created binary features.\n",
      "    - Apply the logistic function (sigmoid) to 'y' to get the final prediction.\n",
      "    - Append the prediction to the 'output' list.\n",
      "\n",
      "- Based on the whole process, we can say that the function takes a DataFrame as input, preprocesses the data, creates new features, and makes predictions based on the created features. The predictions are returned as a NumPy array. The model seems to be a simple logistic regression model that takes into account various factors such as gender, age, passenger class, and embarkation point to make predictions.\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
