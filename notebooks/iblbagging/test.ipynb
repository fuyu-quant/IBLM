{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install --upgrade iblm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iblm                         0.3.54\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list | grep iblm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import iblm\n",
    "#from src.iblm.iblbagging.iblbagging import IBLBaggingModel\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = 10000 # 50〜300\n",
    "num_test_data = 1000\n",
    "sample = num_train_data + num_test_data\n",
    "n_informative = 2\n",
    "n_redundant = 0\n",
    "n_features = n_informative + n_redundant\n",
    "weights = [0.5, 0.5]\n",
    "flip_y=0\n",
    "seed = 3655  # 3655,3656,3657\n",
    "\n",
    "# testデータの個数を揃えるためにtrain_test_splitを使っていない\n",
    "x, y = make_classification(\n",
    "    n_samples = sample,  # データ数\n",
    "    n_features = n_features,  # 特徴量の数\n",
    "    n_informative = n_informative,  # ラベル予測に意味のある特徴量の数\n",
    "    n_redundant = n_redundant,  # 冗長な特徴量\n",
    "    weights = weights,  # [0,1]の割合\n",
    "    flip_y = flip_y, # 逆のラベルに反転する割合\n",
    "    random_state = seed\n",
    "    )\n",
    "\n",
    "x = np.round(x, decimals=3)\n",
    "x = pd.DataFrame(x)\n",
    "y = y.astype(int)\n",
    "\n",
    "x_test = x[0:num_test_data]\n",
    "x_train = x[num_test_data:]\n",
    "\n",
    "y_test = y[:num_test_data]\n",
    "y_train = y[num_test_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iblbg = iblm.IBLBaggingModel(\n",
    "    api_type=\"openai\",\n",
    "    #api_type=\"gemini\",\n",
    "    model_name=\"gpt-4-0125-preview\",\n",
    "    #model_name=\"gemini-pro\",\n",
    "    objective=\"binary\",\n",
    "    num_model=20,\n",
    "    max_sample = 2000,\n",
    "    min_sample = 300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:29:57,345 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Custom simple logistic regression-like model\n",
      "        # Coefficients are manually adjusted based on the dataset characteristics\n",
      "        # Intercept\n",
      "        b0 = 0.5\n",
      "        # Coefficients for the features\n",
      "        b1, b2 = 0.1, 0.15\n",
      "        \n",
      "        # Linear combination of input features\n",
      "        linear_combination = b0 + b1*row[0] + b2*row[1]\n",
      "        # Sigmoid function to map the linear combination to (0,1)\n",
      "        y = 1 / (1 + np.exp(-linear_combination))\n",
      "        \n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:30:18,113 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients, manually adjusted for demonstration\n",
      "        # Intercept\n",
      "        b0 = 0.5\n",
      "        # Coefficients for the features\n",
      "        b1, b2 = 0.3, 0.5\n",
      "        \n",
      "        # Logistic regression formula\n",
      "        z = b0 + (b1 * row[0]) + (b2 * row[1])\n",
      "        y = 1 / (1 + np.exp(-z))\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:30:28,138 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients derived from manual inspection and analysis\n",
      "        # These coefficients are placeholders and should ideally be determined through proper logistic regression analysis\n",
      "        coef_0 = 0.5  # Intercept\n",
      "        coef_1 = 0.25  # Coefficient for the first feature\n",
      "        coef_2 = 0.75  # Coefficient for the second feature\n",
      "        \n",
      "        # Logistic regression formula\n",
      "        z = coef_0 + (coef_1 * row[0]) + (coef_2 * row[1])\n",
      "        y = 1 / (1 + np.exp(-z))  # Sigmoid function to predict the probability\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:30:39,701 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Simple logistic regression model coefficients are dummy and need to be replaced with actual values after model training\n",
      "        # Intercept\n",
      "        b0 = 0.5\n",
      "        # Coefficients for each feature\n",
      "        b1, b2 = 0.7, 0.3\n",
      "        \n",
      "        # Logistic regression model\n",
      "        z = b0 + b1*row[0] + b2*row[1]\n",
      "        y = 1 / (1 + np.exp(-z))\n",
      "        \n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:30:55,352 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        # Simple logistic regression coefficients derived from manual observation and analysis\n",
      "        # These coefficients are placeholders for simplicity and demonstration purposes.\n",
      "        coef_0 = 0.5  # Intercept\n",
      "        coef_1 = 0.25  # Coefficient for the first feature\n",
      "        coef_2 = 0.75  # Coefficient for the second feature\n",
      "\n",
      "        # Logistic regression formula to calculate the probability\n",
      "        # P(y=1) = 1 / (1 + exp(-(coef_0 + coef_1*x1 + coef_2*x2)))\n",
      "        z = coef_0 + coef_1*row[0] + coef_2*row[1]\n",
      "        y = 1 / (1 + np.exp(-z))\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:31:13,333 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients, manually estimated for demonstration\n",
      "        # These coefficients are placeholders and should be replaced with actual values from a trained model\n",
      "        intercept = 0.5  # Intercept (bias)\n",
      "        coef_1 = 0.1  # Coefficient for the first feature\n",
      "        coef_2 = 0.2  # Coefficient for the second feature\n",
      "\n",
      "        # Logistic regression formula to estimate probability\n",
      "        # Note: This is a simplistic approach and not based on actual model training\n",
      "        log_odds = intercept + coef_1 * row[0] + coef_2 * row[1]\n",
      "        odds = np.exp(log_odds)\n",
      "        probability = odds / (1 + odds)\n",
      "\n",
      "        y = probability\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:31:28,806 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Custom simple logistic regression model logic\n",
      "        # Coefficients are hypothetical and derived from an imaginary model training process\n",
      "        coef_0 = 0.5  # Intercept\n",
      "        coef_1 = 1.2  # Coefficient for the first feature\n",
      "        coef_2 = -0.8  # Coefficient for the second feature\n",
      "\n",
      "        # Logistic regression formula to calculate the log-odds\n",
      "        log_odds = coef_0 + coef_1 * row[0] + coef_2 * row[1]\n",
      "        \n",
      "        # Sigmoid function to convert log-odds to probability\n",
      "        probability = 1 / (1 + np.exp(-log_odds))\n",
      "        \n",
      "        output.append(probability)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:31:37,629 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Simple logistic regression coefficients derived from manual observation and analysis\n",
      "        # Intercept\n",
      "        b0 = 0.5\n",
      "        # Coefficients for the features\n",
      "        b1, b2 = 0.25, 0.25\n",
      "        \n",
      "        # Logistic regression model\n",
      "        z = b0 + b1*row[0] + b2*row[1]\n",
      "        y = 1 / (1 + np.exp(-z))\n",
      "        \n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:31:48,692 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "\n",
      "        # Simple logistic regression coefficients, manually estimated from data\n",
      "        coef_0 = 0.5  # Intercept\n",
      "        coef_1 = 0.25  # Coefficient for first feature\n",
      "        coef_2 = 0.75  # Coefficient for second feature\n",
      "\n",
      "        # Logistic regression model\n",
      "        z = coef_0 + coef_1*row[0] + coef_2*row[1]\n",
      "        y = 1 / (1 + np.exp(-z))  # Sigmoid function\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:31:59,285 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients, manually adjusted for demonstration purposes\n",
      "        coef_0 = 0.5  # Intercept\n",
      "        coef_1 = 0.8  # Coefficient for the first feature\n",
      "        coef_2 = -0.4  # Coefficient for the second feature\n",
      "        \n",
      "        # Logistic regression model\n",
      "        z = coef_0 + coef_1 * row[0] + coef_2 * row[1]\n",
      "        y = 1 / (1 + np.exp(-z))  # Sigmoid function\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:32:12,668 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "\n",
      "        # Simple logistic regression coefficients, manually estimated from the dataset\n",
      "        # These coefficients are placeholders and should be replaced with actual values\n",
      "        # obtained from a proper logistic regression analysis on the dataset.\n",
      "        coef_0 = 0.5  # Intercept\n",
      "        coef_1 = 0.8  # Coefficient for the first feature\n",
      "        coef_2 = 0.3  # Coefficient for the second feature\n",
      "\n",
      "        # Logistic regression equation\n",
      "        z = coef_0 + (coef_1 * row[0]) + (coef_2 * row[1])\n",
      "        y = 1 / (1 + np.exp(-z))  # Sigmoid function to get the probability\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:32:23,449 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients, manually estimated for demonstration\n",
      "        # Intercept\n",
      "        b0 = -0.5\n",
      "        # Coefficients for the features\n",
      "        b1, b2 = 0.8, 0.5\n",
      "        \n",
      "        # Logistic regression formula\n",
      "        z = b0 + b1*row[0] + b2*row[1]\n",
      "        y = 1 / (1 + np.exp(-z))\n",
      "        \n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:32:40,888 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients derived from manual inspection and intuition\n",
      "        # These values are placeholders and should ideally be determined through proper model training\n",
      "        coef_0 = 0.5  # Intercept\n",
      "        coef_1 = 0.25  # Coefficient for the first feature\n",
      "        coef_2 = 0.75  # Coefficient for the second feature\n",
      "        \n",
      "        # Logistic regression formula\n",
      "        z = coef_0 + (coef_1 * row[0]) + (coef_2 * row[1])\n",
      "        y = 1 / (1 + np.exp(-z))  # Sigmoid function to predict probability\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:32:52,062 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients derived from data analysis\n",
      "        # These coefficients are placeholders and should be replaced with actual values derived from a logistic regression model\n",
      "        intercept = 0.5  # Placeholder intercept\n",
      "        coef_col1 = 0.1  # Placeholder coefficient for the first column\n",
      "        coef_col2 = 0.2  # Placeholder coefficient for the second column\n",
      "        \n",
      "        # Logistic regression formula\n",
      "        log_odds = intercept + coef_col1 * row[0] + coef_col2 * row[1]\n",
      "        odds = np.exp(log_odds)\n",
      "        probability = odds / (1 + odds)\n",
      "        \n",
      "        y = probability\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:33:02,086 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "\n",
      "        # Simple logistic regression coefficients derived from the dataset\n",
      "        # These coefficients are placeholders and need proper calculation\n",
      "        # from actual logistic regression fitting, which is not shown here.\n",
      "        intercept = 0.5\n",
      "        coef_col1 = 0.1\n",
      "        coef_col2 = 0.2\n",
      "\n",
      "        # Logistic regression formula\n",
      "        log_odds = intercept + coef_col1 * row[0] + coef_col2 * row[1]\n",
      "        odds = np.exp(log_odds)\n",
      "        y = odds / (1 + odds)\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:33:16,703 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Custom simple logistic regression-like model based on observed data characteristics\n",
      "        # This is a placeholder for the actual prediction logic which should be derived from the data\n",
      "        # For demonstration purposes, we use a simple linear combination of features followed by a sigmoid function\n",
      "        # to simulate probability prediction. This is not based on actual model fitting or data analysis.\n",
      "        \n",
      "        # Coefficients are placeholders and do not represent a trained model\n",
      "        coef_0 = 0.5  # Coefficient for feature 0\n",
      "        coef_1 = 0.5  # Coefficient for feature 1\n",
      "        intercept = -0.25  # Intercept\n",
      "        \n",
      "        # Linear combination of input features plus intercept\n",
      "        linear_combination = coef_0 * row[0] + coef_1 * row[1] + intercept\n",
      "        \n",
      "        # Sigmoid function to convert linear combination to probability\n",
      "        y = 1 / (1 + np.exp(-linear_combination))\n",
      "        \n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:33:48,809 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression parameters (these would be learned from data, here just assumed for demonstration)\n",
      "        # These parameters are placeholders and do not represent a trained model.\n",
      "        # In a real scenario, you would train a logistic regression model on your data to find these.\n",
      "        intercept = 0.1\n",
      "        coef_col0 = 0.05\n",
      "        coef_col1 = 0.04\n",
      "        \n",
      "        # Logistic regression equation\n",
      "        log_odds = intercept + coef_col0 * row[0] + coef_col1 * row[1]\n",
      "        odds = np.exp(log_odds)\n",
      "        probability = odds / (1 + odds)\n",
      "        \n",
      "        y = probability\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:33:57,796 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients derived from manual inspection of data\n",
      "        # These values are placeholders and should ideally be determined through proper logistic regression analysis\n",
      "        coef_0 = 0.5  # Intercept\n",
      "        coef_1 = 0.25  # Coefficient for the first feature\n",
      "        coef_2 = 0.75  # Coefficient for the second feature\n",
      "        \n",
      "        # Logistic regression formula to estimate probabilities\n",
      "        z = coef_0 + (coef_1 * row[0]) + (coef_2 * row[1])\n",
      "        y = 1 / (1 + np.exp(-z))  # Sigmoid function\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:34:12,092 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        # Simple logistic regression coefficients are manually estimated based on the dataset characteristics.\n",
      "        # These coefficients are placeholders and need adjustment for real predictive accuracy.\n",
      "        # Intercept and coefficients are hypothetical and for demonstration only.\n",
      "        intercept = 0.5\n",
      "        coef_1 = 0.1\n",
      "        coef_2 = 0.2\n",
      "\n",
      "        # Logistic regression formula to estimate probability\n",
      "        # p = 1 / (1 + e^-(intercept + coef_1*x1 + coef_2*x2))\n",
      "        log_odds = intercept + coef_1*row[0] + coef_2*row[1]\n",
      "        odds = np.exp(log_odds)\n",
      "        probability = odds / (1 + odds)\n",
      "\n",
      "        y = probability\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n",
      "model_20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 03:34:39,209 [iblm.ibl][INFO] (ibl:ibl.py:fit:150)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "def predict(x):\n",
      "    import numpy as np\n",
      "\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "        \n",
      "        # Simple logistic regression coefficients, manually estimated from the dataset\n",
      "        # These coefficients are placeholders. Replace them with your model's coefficients.\n",
      "        intercept = 0.5\n",
      "        coef_col0 = 0.1\n",
      "        coef_col1 = 0.2\n",
      "        \n",
      "        # Logistic regression model\n",
      "        z = intercept + coef_col0*row[0] + coef_col1*row[1]\n",
      "        y = 1 / (1 + np.exp(-z))\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n",
      "#########\n"
     ]
    }
   ],
   "source": [
    "code_models = iblbg.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    temperature=0.3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc': 0.9049601339148055, 'pr_auc': 0.8784086458731357, 'accuracy': 0.811, 'recall': 0.9439071566731141, 'precision': 0.7530864197530864, 'f1_score': 0.8377682403433476}\n",
      "{'roc_auc': 0.9049601339148055, 'pr_auc': 0.8784086458731357, 'accuracy': 0.811, 'recall': 0.9439071566731141, 'precision': 0.7530864197530864, 'f1_score': 0.8377682403433476}\n",
      "{'roc_auc': 0.9049601339148055, 'pr_auc': 0.878409322056068, 'accuracy': 0.811, 'recall': 0.9439071566731141, 'precision': 0.7530864197530864, 'f1_score': 0.8377682403433476}\n",
      "{'roc_auc': 0.9049601339148055, 'pr_auc': 0.8784086458731357, 'accuracy': 0.811, 'recall': 0.9439071566731141, 'precision': 0.7530864197530864, 'f1_score': 0.8377682403433476}\n",
      "{'roc_auc': 0.9049601339148055, 'pr_auc': 0.8784086458731357, 'accuracy': 0.811, 'recall': 0.9439071566731141, 'precision': 0.7530864197530864, 'f1_score': 0.8377682403433476}\n",
      "{'roc_auc': 0.904001025185114, 'pr_auc': 0.8762382702264493, 'accuracy': 0.796, 'recall': 0.9477756286266924, 'precision': 0.7346326836581709, 'f1_score': 0.8277027027027027}\n",
      "{'roc_auc': 0.9031039882103713, 'pr_auc': 0.8741588922899207, 'accuracy': 0.79, 'recall': 0.9497098646034816, 'precision': 0.7274074074074074, 'f1_score': 0.8238255033557047}\n",
      "{'roc_auc': 0.9021629003127616, 'pr_auc': 0.872707142995742, 'accuracy': 0.777, 'recall': 0.9535783365570599, 'precision': 0.7124277456647399, 'f1_score': 0.815550041356493}\n",
      "{'roc_auc': 0.8990432940479193, 'pr_auc': 0.8676636626736242, 'accuracy': 0.776, 'recall': 0.9516441005802708, 'precision': 0.7120115774240231, 'f1_score': 0.8145695364238411}\n",
      "{'roc_auc': 0.8979540348643031, 'pr_auc': 0.8652402437889007, 'accuracy': 0.767, 'recall': 0.9555125725338491, 'precision': 0.7017045454545454, 'f1_score': 0.8091728091728092}\n",
      "{'roc_auc': 0.8973293126854642, 'pr_auc': 0.8640477761356566, 'accuracy': 0.762, 'recall': 0.9593810444874274, 'precision': 0.6956521739130435, 'f1_score': 0.8065040650406504}\n",
      "{'roc_auc': 0.8967766738349532, 'pr_auc': 0.8631497984265156, 'accuracy': 0.757, 'recall': 0.9593810444874274, 'precision': 0.6908077994428969, 'f1_score': 0.8032388663967611}\n",
      "{'roc_auc': 0.8903412344670438, 'pr_auc': 0.8521324415456337, 'accuracy': 0.766, 'recall': 0.9516441005802708, 'precision': 0.7018544935805991, 'f1_score': 0.8078817733990148}\n",
      "{'roc_auc': 0.887501952256809, 'pr_auc': 0.8477910243661814, 'accuracy': 0.764, 'recall': 0.9516441005802708, 'precision': 0.6998577524893315, 'f1_score': 0.8065573770491803}\n",
      "{'roc_auc': 0.8866970217571513, 'pr_auc': 0.8461939151303753, 'accuracy': 0.764, 'recall': 0.9516441005802708, 'precision': 0.6998577524893315, 'f1_score': 0.8065573770491803}\n",
      "{'roc_auc': 0.8763210271073362, 'pr_auc': 0.828733271622079, 'accuracy': 0.775, 'recall': 0.941972920696325, 'precision': 0.7140762463343109, 'f1_score': 0.8123436196830692}\n",
      "{'roc_auc': 0.8652642454677608, 'pr_auc': 0.8146500222806243, 'accuracy': 0.771, 'recall': 0.9342359767891683, 'precision': 0.7123893805309734, 'f1_score': 0.80836820083682}\n",
      "{'roc_auc': 0.8567664219838134, 'pr_auc': 0.8041502717275664, 'accuracy': 0.768, 'recall': 0.9303675048355899, 'precision': 0.7104874446085672, 'f1_score': 0.8056951423785594}\n",
      "{'roc_auc': 0.8379967242131905, 'pr_auc': 0.7787685254569621, 'accuracy': 0.753, 'recall': 0.9264990328820116, 'precision': 0.6962209302325582, 'f1_score': 0.7950207468879668}\n"
     ]
    }
   ],
   "source": [
    "top_model = 20\n",
    "\n",
    "for i in range(1, top_model):\n",
    "    y_pred = iblbg.predict_(x_test, i)\n",
    "    print(iblbg.evaluate(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
