{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo dataset\n",
    "* Get sample data [here](https://github.com/fuyu-quant/IBLM/tree/main/datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/IBLM/blob/main/examples/iblmodel_pseudodata.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/fuyu-quant/IBLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.21\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution('IBLM').version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from iblm import IBLMClassifier\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pseudodata_4f_train.csv'\n",
    "#file_name = 'pseudodata_8f_train.csv'\n",
    "#file_name = 'pseudodata_12f_train.csv'\n",
    "\n",
    "#df = pd.read_csv(f'/content/{file_name}}')\n",
    "df = pd.read_csv(f'../datasets/{file_name}')\n",
    "x_train = df.drop(df.columns[-1], axis=1)\n",
    "y_train = df[df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {\n",
    "    'columns_name': True\n",
    "    }\n",
    "\n",
    "iblm = IBLMClassifier(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/content/'\n",
    "file_path = './model_code/'\n",
    "\n",
    "model = iblm.fit(x_train, y_train, model_name = 'pseudodata', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "def predict(x):\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        # Please describe the process required to make the prediction below.\n",
      "\n",
      "        # Calculate the weighted sum of the features\n",
      "        weighted_sum = row['A'] * 0.25 + row['B'] * 0.35 + row['C'] * 0.2 + row['D'] * 0.15\n",
      "\n",
      "        # Apply the sigmoid function to the weighted sum to get the probability\n",
      "        y = 1 / (1 + np.exp(-weighted_sum))\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n"
     ]
    }
   ],
   "source": [
    "# Code of the model created\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'pseudodata_4f_test.csv'\n",
    "#file_name = 'pseudodata_8f_test.csv'\n",
    "#file_name = 'pseudodata_12f_test.csv'\n",
    "\n",
    "#df = pd.read_csv(f'/content/{file_name}}')\n",
    "df = pd.read_csv(f'../datasets/{file_name}')\n",
    "x_test = df.drop(df.columns[-1], axis=1)\n",
    "y_test = df[df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = iblm.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6077\n",
      "Precision: 0.6504\n",
      "Recall: 0.4863\n",
      "F1 score: 0.5565\n",
      "ROC-AUC: 0.7625\n"
     ]
    }
   ],
   "source": [
    "accuracy = round(accuracy_score(y_test, y_pred),4)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = round(precision_score(y_test, y_pred),4)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = round(recall_score(y_test, y_pred),4)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = round(f1_score(y_test, y_pred),4)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = round(roc_auc_score(y_test, y_proba),4)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from external files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pseudodata\n",
    "\n",
    "y_proba = pseudodata.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.415\n",
      "Precision: 0.43103448275862066\n",
      "Recall: 0.49504950495049505\n",
      "F1 score: 0.4608294930875576\n",
      "ROC-AUC: 0.35973597359735976\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 881\n",
      "\tPrompt Tokens: 537\n",
      "\tCompletion Tokens: 344\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.036750000000000005\n"
     ]
    }
   ],
   "source": [
    "description = iblm.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Data preprocessing:\n",
      "    - Fill missing 'age' values with the median age.\n",
      "    - Fill missing 'fare' values with the median fare.\n",
      "    - Fill missing 'embarked' values with the mode (most frequent) of the 'embarked' column.\n",
      "\n",
      "- Feature creation:\n",
      "    - Create a new binary feature 'is_female' based on the 'sex' column.\n",
      "    - Create a new binary feature 'is_child' based on the 'age' column.\n",
      "    - Create a new binary feature 'is_adult_male' based on the 'adult_male' column.\n",
      "    - Create a new binary feature 'is_alone' based on the 'alone' column.\n",
      "    - Create new binary features 'is_first_class', 'is_second_class', and 'is_third_class' based on the 'pclass' column.\n",
      "    - Create new binary features 'embarked_C', 'embarked_Q', and 'embarked_S' based on the 'embarked' column.\n",
      "\n",
      "- Prediction logic:\n",
      "    - Initialize a variable 'y' to 0.\n",
      "    - Add or subtract weights to 'y' based on the created binary features.\n",
      "    - Apply the logistic function (sigmoid) to 'y' to get the final prediction.\n",
      "    - Append the prediction to the 'output' list.\n",
      "\n",
      "- Based on the whole process, we can say that the function takes a DataFrame as input, preprocesses the data, creates new features, and makes predictions based on the created features. The predictions are returned as a NumPy array. The model seems to be a simple logistic regression model that takes into account various factors such as gender, age, passenger class, and embarkation point to make predictions.\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7618\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 148\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23298\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7642\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 172\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23442\n",
      "> Start of model creating.\n",
      "Tokens Used: 7599\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 129\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23184\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7643\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 173\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23448\n",
      "> Start of model creating.\n",
      "Tokens Used: 7616\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 146\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23285999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7668\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 198\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23598\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7618\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 148\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23298\n",
      "> Start of model creating.\n",
      "Tokens Used: 7643\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 173\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23448\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7630\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 160\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.2337\n",
      "> Start of model creating.\n",
      "Tokens Used: 7630\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 160\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.2337\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n",
      "> Start of model creating.\n",
      "Tokens Used: 7629\n",
      "\tPrompt Tokens: 7470\n",
      "\tCompletion Tokens: 159\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23364\n"
     ]
    }
   ],
   "source": [
    "#file_path = '/content/'\n",
    "file_path = './code_model/'\n",
    "\n",
    "for i in range(30):\n",
    "    model = iblm.fit(x_train, y_train, model_name = f'pseudodata_{i}_', file_path=file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
