{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset\n",
    "* Get sample data [here](https://github.com/fuyu-quant/IBLM/tree/main/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/fuyu-quant/IBLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.1\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution('IBLM').version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from iblm import IBLMClassifier\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "\n",
    "#df = pd.read_csv('../data/pseudodata_train.csv')\n",
    "df = pd.read_csv(f'../data/titanic/titanicdata_{n}_train.csv')\n",
    "x_train = df.drop('survived', axis=1)\n",
    "y_train = df['survived']\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>...</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass   age  sibsp  parch     fare  sex_female  sex_male  embarked_C  \\\n",
       "0       2  27.0      0      0  10.5000           1         0           0   \n",
       "1       2   7.0      0      2  26.2500           1         0           0   \n",
       "2       2  29.0      1      0  26.0000           1         0           0   \n",
       "3       3  27.0      0      0   7.7958           0         1           0   \n",
       "4       3  20.0      0      0   9.2250           0         1           0   \n",
       "5       3  21.0      0      0   8.4333           0         1           0   \n",
       "6       2  28.0      0      0   0.0000           0         1           0   \n",
       "7       3  24.0      0      0   8.8500           1         0           0   \n",
       "\n",
       "   embarked_Q  embarked_S  ...  deck_A  deck_B  deck_C  deck_D  deck_E  \\\n",
       "0           0           1  ...       0       0       0       0       1   \n",
       "1           0           1  ...       0       0       0       0       0   \n",
       "2           0           1  ...       0       0       0       0       0   \n",
       "3           0           1  ...       0       0       0       0       0   \n",
       "4           0           1  ...       0       0       0       0       0   \n",
       "5           0           1  ...       0       0       0       0       0   \n",
       "6           0           1  ...       0       0       0       0       0   \n",
       "7           0           1  ...       0       0       0       0       0   \n",
       "\n",
       "   deck_F  deck_G  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "0       0       0                      0                       0   \n",
       "1       0       0                      0                       0   \n",
       "2       0       0                      0                       0   \n",
       "3       0       0                      0                       0   \n",
       "4       0       0                      0                       0   \n",
       "5       0       0                      0                       0   \n",
       "6       0       0                      0                       0   \n",
       "7       0       0                      0                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        1  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  \n",
       "5                        1  \n",
       "6                        1  \n",
       "7                        1  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {'columns_name': True}\n",
    "\n",
    "iblm = IBLMClassifier(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:8\n",
      "> Start of model creating.\n",
      "Tokens Used: 2096\n",
      "\tPrompt Tokens: 1554\n",
      "\tCompletion Tokens: 542\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.07913999999999999\n"
     ]
    }
   ],
   "source": [
    "file_path = '../models/titanic/'\n",
    "\n",
    "print(f'Number of data:{len(x_train)}')\n",
    "model = iblm.fit(x_train, y_train, model_name = 'titanic', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "def predict(x):\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        \n",
      "        # Prediction logic\n",
      "        pclass = row['pclass']\n",
      "        age = row['age']\n",
      "        fare = row['fare']\n",
      "        sex_female = row['sex_female']\n",
      "        embarked_C = row['embarked_C']\n",
      "        embarked_Q = row['embarked_Q']\n",
      "        embarked_S = row['embarked_S']\n",
      "        alive_yes = row['alive_yes']\n",
      "        alone_True = row['alone_True']\n",
      "        adult_male_True = row['adult_male_True']\n",
      "        who_child = row['who_child']\n",
      "        who_woman = row['who_woman']\n",
      "        class_First = row['class_First']\n",
      "        class_Second = row['class_Second']\n",
      "        class_Third = row['class_Third']\n",
      "        embark_town_Cherbourg = row['embark_town_Cherbourg']\n",
      "        embark_town_Queenstown = row['embark_town_Queenstown']\n",
      "        embark_town_Southampton = row['embark_town_Southampton']\n",
      "\n",
      "        # Calculate probability based on the given data\n",
      "        prob = 0\n",
      "        if sex_female:\n",
      "            prob += 0.6\n",
      "        if pclass == 1:\n",
      "            prob += 0.3\n",
      "        elif pclass == 2:\n",
      "            prob += 0.1\n",
      "        if age <= 16:\n",
      "            prob += 0.2\n",
      "        if fare > 50:\n",
      "            prob += 0.1\n",
      "        if embarked_C:\n",
      "            prob += 0.1\n",
      "        if alive_yes:\n",
      "            prob += 0.3\n",
      "        if alone_True:\n",
      "            prob -= 0.1\n",
      "        if adult_male_True:\n",
      "            prob -= 0.2\n",
      "        if who_child:\n",
      "            prob += 0.2\n",
      "        if who_woman:\n",
      "            prob += 0.1\n",
      "        if class_First:\n",
      "            prob += 0.2\n",
      "        if class_Second:\n",
      "            prob += 0.1\n",
      "        if embark_town_Cherbourg:\n",
      "            prob += 0.1\n",
      "        if embark_town_Queenstown:\n",
      "            prob += 0.05\n",
      "        if embark_town_Southampton:\n",
      "            prob += 0.05\n",
      "\n",
      "        # Normalize probability to be between 0 and 1\n",
      "        y = min(max(prob, 0), 1)\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(y)\n",
      "    return np.array(output)\n"
     ]
    }
   ],
   "source": [
    "# Code of the model created\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../data/titanic/titanicdata_{n}_test.csv')\n",
    "x_test = df.drop('survived', axis=1)\n",
    "y_test = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = iblm.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8471121177802945\n",
      "Precision: 0.7650130548302873\n",
      "Recall: 0.8668639053254438\n",
      "F1 score: 0.812760055478502\n",
      "ROC-AUC: 0.9261793605124586\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction from external files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_code\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtitanic_1_\u001b[39;00m  \u001b[38;5;28;01mimport\u001b[39;00m predict\n\u001b[1;32m      3\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m titanic\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_proba \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from model_code import titanic\n",
    "\n",
    "y_proba = titanic.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Precision: 0.3956043956043956\n",
      "Recall: 1.0\n",
      "F1 score: 0.5669291338582677\n",
      "ROC-AUC: 0.9197048611111112\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 896\n",
      "\tPrompt Tokens: 341\n",
      "\tCompletion Tokens: 555\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04353\n"
     ]
    }
   ],
   "source": [
    "description = iblm.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- First, the function `predict` takes a DataFrame `x` as input and creates a copy of it named `df`. The columns of `df` are then renamed to be integer indices.\n",
      "\n",
      "- The function then initializes an empty list called `output` to store the predictions.\n",
      "\n",
      "- For each row in the DataFrame `df`, the function extracts the following features:\n",
      "  - `pclass`: Passenger class (First, Second, or Third)\n",
      "  - `sex`: Gender of the passenger (male or female)\n",
      "  - `age`: Age of the passenger\n",
      "  - `fare`: Ticket fare paid by the passenger\n",
      "  - `embarked`: Port of embarkation (C, Q, or S)\n",
      "  - `alone`: Whether the passenger is traveling alone or not (True or False)\n",
      "\n",
      "- The prediction logic is then applied to these features, and a variable `y` is initialized to 0.\n",
      "\n",
      "- The following conditions are checked and the corresponding values are added to `y`:\n",
      "  - If `pclass` is 'First', add 0.3 to `y`.\n",
      "  - If `pclass` is 'Second', add 0.15 to `y`.\n",
      "  - If `sex` is 'female', add 0.35 to `y`.\n",
      "  - If `age` is less than or equal to 16, add 0.1 to `y`.\n",
      "  - If `age` is greater than 16 and less than or equal to 32, add 0.05 to `y`.\n",
      "  - If `fare` is greater than 50, add 0.1 to `y`.\n",
      "  - If `embarked` is 'C', add 0.05 to `y`.\n",
      "  - If `alone` is True, add 0.05 to `y`.\n",
      "\n",
      "- After processing all the conditions, the value of `y` is transformed using the logistic function: `y = 1 / (1 + np.exp(-y))`. This transformation maps `y` to a value between 0 and 1, which can be interpreted as a probability.\n",
      "\n",
      "- The transformed value of `y` is then appended to the `output` list.\n",
      "\n",
      "- Once all rows in the DataFrame have been processed, the `output` list is converted to a NumPy array and returned by the function.\n",
      "\n",
      "Based on the whole process, we can say that the function `predict` takes a DataFrame containing passenger information and returns an array of probabilities representing the likelihood of each passenger meeting certain criteria (e.g., survival). The prediction is based on a simple rule-based model that considers passenger class, gender, age, fare, port of embarkation, and whether the passenger is traveling alone.\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model creating.\n",
      "Tokens Used: 7571\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 332\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23708999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7690\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 451\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24422999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7577\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 338\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23744999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7653\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 414\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24200999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7692\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 453\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24434999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7570\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 331\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23702999999999996\n",
      "> Start of model creating.\n",
      "Tokens Used: 7692\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 453\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24434999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7692\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 453\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24434999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7577\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 338\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23744999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7647\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 408\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24164999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7688\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 449\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24410999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7692\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 453\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24434999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7541\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 302\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23528999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7652\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 413\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24194999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7576\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 337\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23738999999999996\n",
      "> Start of model creating.\n",
      "Tokens Used: 7637\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 398\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24105\n",
      "> Start of model creating.\n",
      "Tokens Used: 7598\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 359\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23870999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7542\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 303\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23534999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7692\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 453\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24434999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7649\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 410\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24176999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7649\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 410\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24176999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7758\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 519\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24830999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7705\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 466\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24512999999999996\n",
      "> Start of model creating.\n",
      "Tokens Used: 7692\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 453\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24434999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7659\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 420\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24236999999999997\n",
      "> Start of model creating.\n",
      "Tokens Used: 7741\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 502\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24728999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7542\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 303\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23534999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7692\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 453\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24434999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7598\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 359\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.23870999999999998\n",
      "> Start of model creating.\n",
      "Tokens Used: 7649\n",
      "\tPrompt Tokens: 7239\n",
      "\tCompletion Tokens: 410\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.24176999999999998\n"
     ]
    }
   ],
   "source": [
    "#file_path = '/content/'\n",
    "file_path = './model_code/'\n",
    "\n",
    "for i in range(30):\n",
    "    model = iblm.fit(x_train, y_train, model_name = f'titanic_{i}_', file_path=file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('iblm-L6oop2Mj-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67008fb9323ab6c1c90f5d9822582dbef34eff0db475eec3af4e0e9456757ebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
