{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset\n",
    "* Get sample data [here](https://github.com/fuyu-quant/IBLM/tree/main/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/fuyu-quant/IBLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.1\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution('IBLM').version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from iblm import IBLMClassifier\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "\n",
    "df = pd.read_csv(f'../data/titanic/titanic_{n}_train.csv')\n",
    "x_train = df.drop('survived', axis=1)\n",
    "y_train = df['survived']\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>...</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7958</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass   age  sibsp  parch     fare  sex_female  sex_male  embarked_C  \\\n",
       "0       2  27.0      0      0  10.5000        True     False       False   \n",
       "1       2   7.0      0      2  26.2500        True     False       False   \n",
       "2       2  29.0      1      0  26.0000        True     False       False   \n",
       "3       3  27.0      0      0   7.7958       False      True       False   \n",
       "4       3  20.0      0      0   9.2250       False      True       False   \n",
       "5       3  21.0      0      0   8.4333       False      True       False   \n",
       "6       2  28.0      0      0   0.0000       False      True       False   \n",
       "7       3  24.0      0      0   8.8500        True     False       False   \n",
       "\n",
       "   embarked_Q  embarked_S  ...  deck_A  deck_B  deck_C  deck_D  deck_E  \\\n",
       "0       False        True  ...   False   False   False   False    True   \n",
       "1       False        True  ...   False   False   False   False   False   \n",
       "2       False        True  ...   False   False   False   False   False   \n",
       "3       False        True  ...   False   False   False   False   False   \n",
       "4       False        True  ...   False   False   False   False   False   \n",
       "5       False        True  ...   False   False   False   False   False   \n",
       "6       False        True  ...   False   False   False   False   False   \n",
       "7       False        True  ...   False   False   False   False   False   \n",
       "\n",
       "   deck_F  deck_G  embark_town_Cherbourg  embark_town_Queenstown  \\\n",
       "0   False   False                  False                   False   \n",
       "1   False   False                  False                   False   \n",
       "2   False   False                  False                   False   \n",
       "3   False   False                  False                   False   \n",
       "4   False   False                  False                   False   \n",
       "5   False   False                  False                   False   \n",
       "6   False   False                  False                   False   \n",
       "7   False   False                  False                   False   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                     True  \n",
       "1                     True  \n",
       "2                     True  \n",
       "3                     True  \n",
       "4                     True  \n",
       "5                     True  \n",
       "6                     True  \n",
       "7                     True  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {'columns_name': True}\n",
    "\n",
    "iblm = IBLMClassifier(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data:8\n",
      "> Start of model creating.\n",
      "Tokens Used: 1357\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 542\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05696999999999999\n"
     ]
    }
   ],
   "source": [
    "file_path = '../models/titanic/'\n",
    "\n",
    "print(f'Number of data:{len(x_train)}')\n",
    "model = iblm.fit(x_train, y_train, model_name = 'titanic', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "\n",
      "def predict(x):\n",
      "    df = x.copy()\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        # Do not change the code before this point.\n",
      "        \n",
      "        # Calculate the probability based on the given data\n",
      "        pclass = row['pclass']\n",
      "        age = row['age']\n",
      "        sibsp = row['sibsp']\n",
      "        parch = row['parch']\n",
      "        fare = row['fare']\n",
      "        sex_female = row['sex_female']\n",
      "        sex_male = row['sex_male']\n",
      "        embarked_C = row['embarked_C']\n",
      "        embarked_Q = row['embarked_Q']\n",
      "        embarked_S = row['embarked_S']\n",
      "        alive_no = row['alive_no']\n",
      "        alive_yes = row['alive_yes']\n",
      "        alone_False = row['alone_False']\n",
      "        alone_True = row['alone_True']\n",
      "        adult_male_False = row['adult_male_False']\n",
      "        adult_male_True = row['adult_male_True']\n",
      "        who_child = row['who_child']\n",
      "        who_man = row['who_man']\n",
      "        who_woman = row['who_woman']\n",
      "        class_First = row['class_First']\n",
      "        class_Second = row['class_Second']\n",
      "        class_Third = row['class_Third']\n",
      "        deck_A = row['deck_A']\n",
      "        deck_B = row['deck_B']\n",
      "        deck_C = row['deck_C']\n",
      "        deck_D = row['deck_D']\n",
      "        deck_E = row['deck_E']\n",
      "        deck_F = row['deck_F']\n",
      "        deck_G = row['deck_G']\n",
      "        embark_town_Cherbourg = row['embark_town_Cherbourg']\n",
      "        embark_town_Queenstown = row['embark_town_Queenstown']\n",
      "        embark_town_Southampton = row['embark_town_Southampton']\n",
      "\n",
      "        # Calculate the probability based on the given features\n",
      "        prob = 0\n",
      "        if sex_female:\n",
      "            prob += 0.6\n",
      "        if class_First:\n",
      "            prob += 0.3\n",
      "        elif class_Second:\n",
      "            prob += 0.2\n",
      "        if embarked_C:\n",
      "            prob += 0.1\n",
      "        if fare > 50:\n",
      "            prob += 0.1\n",
      "        if age < 18:\n",
      "            prob += 0.1\n",
      "        if sibsp == 0 and parch == 0:\n",
      "            prob += 0.1\n",
      "\n",
      "        # Normalize the probability\n",
      "        prob = min(1, prob)\n",
      "\n",
      "        # Do not change the code after this point.\n",
      "        output.append(prob)\n",
      "    return np.array(output)\n"
     ]
    }
   ],
   "source": [
    "# Code of the model created\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../data/titanic/titanic_{n}_test.csv')\n",
    "x_test = df.drop('survived', axis=1)\n",
    "y_test = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = iblm.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7859569648924122\n",
      "Precision: 0.7350157728706624\n",
      "Recall: 0.6893491124260355\n",
      "F1 score: 0.7114503816793892\n",
      "ROC-AUC: 0.8445876988219966\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model creating.\n",
      "Tokens Used: 1134\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 319\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.043590000000000004\n",
      "> Start of model creating.\n",
      "Tokens Used: 1326\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 511\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05511\n",
      "> Start of model creating.\n",
      "Tokens Used: 1197\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 382\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.047369999999999995\n",
      "> Start of model creating.\n",
      "Tokens Used: 1407\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 592\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.059969999999999996\n",
      "> Start of model creating.\n",
      "Tokens Used: 1638\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 823\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.07382999999999999\n",
      "> Start of model creating.\n",
      "Tokens Used: 1421\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 606\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.060809999999999996\n",
      "> Start of model creating.\n",
      "Tokens Used: 1293\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 478\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05313\n",
      "> Start of model creating.\n",
      "Tokens Used: 1139\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 324\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04389\n",
      "> Start of model creating.\n",
      "Tokens Used: 1407\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 592\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.059969999999999996\n",
      "> Start of model creating.\n",
      "Tokens Used: 1305\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 490\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.053849999999999995\n",
      "> Start of model creating.\n",
      "Tokens Used: 1244\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 429\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05019\n",
      "> Start of model creating.\n",
      "Tokens Used: 1354\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 539\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05678999999999999\n",
      "> Start of model creating.\n",
      "Tokens Used: 1279\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 464\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05229\n",
      "> Start of model creating.\n",
      "Tokens Used: 1182\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 367\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04647\n",
      "> Start of model creating.\n",
      "Tokens Used: 1334\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 519\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05559\n",
      "> Start of model creating.\n",
      "Tokens Used: 1176\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 361\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04611\n",
      "> Start of model creating.\n",
      "Tokens Used: 1282\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 467\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05247\n",
      "> Start of model creating.\n",
      "Tokens Used: 1200\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 385\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.047549999999999995\n",
      "> Start of model creating.\n",
      "Tokens Used: 1229\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 414\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04929\n",
      "> Start of model creating.\n",
      "Tokens Used: 1137\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 322\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04377\n",
      "> Start of model creating.\n",
      "Tokens Used: 1323\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 508\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05493\n",
      "> Start of model creating.\n",
      "Tokens Used: 1477\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 662\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.06417\n",
      "> Start of model creating.\n",
      "Tokens Used: 1498\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 683\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.06542999999999999\n",
      "> Start of model creating.\n",
      "Tokens Used: 1331\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 516\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05541\n",
      "> Start of model creating.\n",
      "Tokens Used: 1139\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 324\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04389\n",
      "> Start of model creating.\n",
      "Tokens Used: 1357\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 542\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05696999999999999\n",
      "> Start of model creating.\n",
      "Tokens Used: 1313\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 498\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05433\n",
      "> Start of model creating.\n",
      "Tokens Used: 1331\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 516\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.05541\n",
      "> Start of model creating.\n",
      "Tokens Used: 1114\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 299\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04239\n",
      "> Start of model creating.\n",
      "Tokens Used: 1088\n",
      "\tPrompt Tokens: 815\n",
      "\tCompletion Tokens: 273\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04083\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "\n",
    "df = pd.read_csv(f'../data/titanic/titanic_{n}_train.csv')\n",
    "x_train = df.drop('survived', axis=1)\n",
    "y_train = df['survived']\n",
    "\n",
    "file_path = '../models/titanic/'\n",
    "for i in range(1,31):\n",
    "    model = iblm.fit(x_train, y_train, model_name = f'titanic_{n}_{i}', file_path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'other_dir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.titanic.titanic_8_1 as codemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codemodel.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../data/titanic/titanic_{n}_test.csv')\n",
    "x_test = df.drop('survived', axis=1)\n",
    "y_test = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = iblm.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 3\n",
    "import_file = f'import models.titanic.titanic_8_{i} as codemodel'\n",
    "\n",
    "exec(import_file)\n",
    "\n",
    "y_proba = codemodel.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.23085938, -0.59898477, -1.17026562, -0.88832488, -1.22539062,\n",
       "       -1.21554687, -1.14748437, -1.18798438, -1.18798438, -0.85617597,\n",
       "       -1.17026562, -0.99166062, -1.22539062, -1.22320312, -1.14748437,\n",
       "       -1.13837187, -1.16317812, -1.20176562, -1.18798438, -1.10647812,\n",
       "       -1.18247188, -1.20176562, -1.10647812, -1.13837188, -1.13837187,\n",
       "       -1.16317812, -1.20570312, -1.13837187, -1.13837188, -1.22539062,\n",
       "       -1.04906937, -0.59898477, -1.13837188, -1.21554687, -1.04906937,\n",
       "       -1.17026562, -1.20570312, -1.22539062, -1.18798438, -1.10647812,\n",
       "       -1.18798438, -1.07982912, -1.20570312, -0.85617597, -1.13837188,\n",
       "       -1.22539062, -1.22320312, -1.13837188, -1.20176562, -1.18798438,\n",
       "       -1.18798438, -1.22539062, -0.78498912, -1.07982912, -1.10647812,\n",
       "       -1.13837188, -1.09372063, -1.20570312, -1.03120887, -1.18798438,\n",
       "       -1.20570312, -0.78498912, -1.17026562, -1.18798438, -1.04906937,\n",
       "       -1.21554687, -1.09372063, -1.22539062, -1.18798438, -1.23085938,\n",
       "       -1.20176562, -1.13837187, -1.16317812, -1.21554687, -1.20570312,\n",
       "       -1.22539062, -1.22539062, -1.22539062, -1.12844937, -1.17026562,\n",
       "       -1.22539062, -1.22539062, -1.13837188, -1.13837188, -1.09372063,\n",
       "       -1.18798438, -1.21554687, -1.22539062, -0.88832488, -1.22539062,\n",
       "       -1.22539062, -1.22539062, -1.17026562, -1.22320312, -1.23242188,\n",
       "       -1.22539062, -1.10647812, -1.04906937, -1.07982912, -1.19747812,\n",
       "       -1.17026562, -1.22539062, -1.13837187, -1.22539062, -1.23085938,\n",
       "       -1.22539062, -1.17026562, -1.22539062, -1.22539062, -1.12844937,\n",
       "       -1.14748437, -1.10647812, -1.22539062, -1.18798438, -1.10647812,\n",
       "       -1.22539062, -1.22539062, -1.19747812, -1.04906937, -1.13837187,\n",
       "       -1.18247188, -1.22539062, -1.15546062, -1.09372063, -1.17026562,\n",
       "       -1.17026562, -1.21554687, -1.22539062, -1.09372063, -1.23242188,\n",
       "       -1.20570312, -1.22539062, -1.20570312, -1.20176562, -1.16317812,\n",
       "       -0.96869713, -1.13837187, -1.21835937, -0.99166062, -1.13837187,\n",
       "       -1.17026562, -1.18798438, -1.21554687, -1.20176562, -1.19747812,\n",
       "       -1.13837187, -1.19747812, -1.21554687, -1.21554687, -0.88832488,\n",
       "       -1.23242188, -1.23632812, -1.22539062, -1.10647812, -1.10647812,\n",
       "       -1.22539062, -1.22539062, -1.21554687, -1.23632812, -1.09372063,\n",
       "       -1.22539062, -1.22539062, -1.18798438, -1.18798438, -0.88832488,\n",
       "       -1.18798438, -1.13837188, -1.20570312, -1.17026562, -1.16317812,\n",
       "       -1.17026562, -1.22539062, -1.10647812, -1.23085938, -1.22320312,\n",
       "       -0.78498912, -1.20176562, -1.22539062, -1.13837187, -1.16317812,\n",
       "       -1.18798438, -1.12844937, -1.13837187, -1.10647812, -1.16317812,\n",
       "       -1.17026562, -1.22320312, -1.22539062, -1.09372063, -1.20176562,\n",
       "       -1.18798438, -1.12844937, -0.78498912, -0.65212887, -1.21554687,\n",
       "       -1.23632812, -1.13837188, -1.09372063, -1.22539062, -1.21554687,\n",
       "       -1.22539062, -1.21835937, -1.22539062, -1.17026562, -1.23085938,\n",
       "       -1.20570312, -1.10647812, -1.04906937, -1.22539062, -1.03120887,\n",
       "       -1.22539062, -1.20176562, -1.22320312, -0.59898477, -1.17026562,\n",
       "       -1.21248437, -0.41298042, -1.20176562, -1.21835937, -1.20176562,\n",
       "       -1.23242188, -1.22539062, -1.13837187, -1.22539062, -1.20176562,\n",
       "       -1.22539062, -1.20176562, -1.16317812, -0.88832488, -1.22539062,\n",
       "       -1.21554687, -1.13837187, -1.20176562, -1.17026562, -1.21248437,\n",
       "       -1.03120887, -1.20176562, -1.20176562, -1.13837187, -1.16317812,\n",
       "       -1.20176562, -1.22539062, -1.20570312, -1.13837188, -1.17026562,\n",
       "       -1.12844937, -1.13837187, -1.21248437, -1.22539062, -1.18798438,\n",
       "       -1.17026562, -1.23085938, -1.18798438, -1.13837187, -0.41298042,\n",
       "       -0.78498912, -0.41298042, -1.12844937, -1.21554687, -1.18798438,\n",
       "       -1.17026562, -1.17026562, -1.13837188, -1.20176562, -1.21554687,\n",
       "       -1.23085938, -0.99166062, -0.78498912, -1.13837188, -1.22539062,\n",
       "       -1.16317812, -1.09372063, -1.13837188, -0.99166062, -1.19304688,\n",
       "       -1.20176562, -1.16317812, -1.16317812, -1.22539062, -1.22539062,\n",
       "       -1.21835937, -1.22539062, -1.13837188, -1.20570312, -1.22539062,\n",
       "       -1.22539062, -1.21554687, -1.13837188, -0.78498912, -0.59898477,\n",
       "       -1.16317812, -1.22539062, -1.04906937, -1.20570312, -0.78498912,\n",
       "       -1.13837188, -0.78498912, -1.13837188, -1.21248437, -1.22539062,\n",
       "       -1.03120887, -1.22539062, -0.99166062, -0.41298042, -0.59898477,\n",
       "       -1.15546062, -0.41298042, -0.41298042, -0.59898477, -1.07982912,\n",
       "       -1.22539062, -1.21248437, -1.17026562, -1.07982912, -1.21554687,\n",
       "       -0.88832488, -0.59898477, -1.22539062, -1.22539062, -1.03120887,\n",
       "       -1.07982912, -1.21554687, -0.41298042, -1.23242188, -1.09372063,\n",
       "       -1.16317812, -0.41298042, -1.12844937, -1.17026562, -1.13837187,\n",
       "       -1.22539062, -0.88832488, -1.22539062, -1.13837187, -0.65212887,\n",
       "       -1.23242188, -1.17026562, -1.12844937, -0.88832488, -1.20176562,\n",
       "       -1.20176562, -1.20176562, -1.09372063, -1.09372063, -1.18798438,\n",
       "       -1.20570312, -1.23242188, -1.22539062, -1.13837188, -1.17026562,\n",
       "       -1.23085938, -1.20570312, -1.22539062, -0.88832488, -1.09372063,\n",
       "       -1.13837188, -1.13837188, -1.22320312, -1.15546062, -1.17026562,\n",
       "       -1.22539062, -1.22320312, -1.22539062, -0.78498912, -1.10647812,\n",
       "       -1.13837188, -0.41298042, -1.04906937, -1.23085938, -1.22539062,\n",
       "       -0.99166062, -1.13837187, -0.59898477, -1.17026562, -1.04906937,\n",
       "       -1.20570312, -1.22539062, -0.65212887, -1.10647812, -1.22539062,\n",
       "       -0.88832488, -1.22539062, -1.16317812, -1.18798438, -1.09372063,\n",
       "       -1.21554687, -0.96869713, -1.13837187, -1.22539062, -1.23085938,\n",
       "       -0.59898477, -1.18798438, -1.22539062, -1.17026562, -1.20176562,\n",
       "       -1.20176562, -1.09372063, -1.22539062, -1.22539062, -1.18798438,\n",
       "       -1.23085938, -1.17026562, -1.19747812, -1.23242188, -1.16317812,\n",
       "       -1.22539062, -1.16317812, -1.22539062, -1.21554687, -0.74365482,\n",
       "       -1.20176562, -1.23242188, -1.17026562, -1.07982912, -1.12844937,\n",
       "       -1.20176562, -1.13837187, -1.20570312, -1.21554687, -1.22539062,\n",
       "       -1.18798438, -1.22320312, -1.22539062, -1.07982912, -1.03120887,\n",
       "       -1.21554687, -1.22539062, -1.13837188, -1.18798438, -1.12844937,\n",
       "       -1.22539062, -1.17026562, -0.78498912, -1.16317812, -1.12844937,\n",
       "       -1.17026562, -1.20176562, -1.12844937, -1.22539062, -1.23085938,\n",
       "       -1.09372063, -1.22539062, -0.99166062, -1.09372063, -1.13837188,\n",
       "       -1.10647812, -1.17026562, -1.19747812, -1.23085938, -1.04906937,\n",
       "       -1.10647812, -1.22539062, -1.20570312, -1.17026562, -0.88832488,\n",
       "       -1.13837187, -1.21554687, -1.17026562, -1.22539062, -1.17026562,\n",
       "       -1.21554687, -1.22539062, -1.22539062, -1.20176562, -1.17026562,\n",
       "       -1.21554687, -1.10647812, -1.22539062, -1.22539062, -1.07982912,\n",
       "       -0.96869713, -1.17026562, -1.10647812, -1.19747812, -1.23085938,\n",
       "       -1.22539062, -1.17026562, -1.18798438, -1.20176562, -1.23242188,\n",
       "       -1.19304688, -1.04906937, -1.16317812, -0.88832488, -1.10647812,\n",
       "       -1.22539062, -1.20570312, -1.23085938, -1.22539062, -1.17026562,\n",
       "       -1.10647812, -1.22539062, -1.20570312, -0.78498912, -1.22539062,\n",
       "       -0.88832488, -1.22539062, -1.22539062, -1.13837188, -1.13837188,\n",
       "       -1.17026562, -0.65212887, -1.04906937, -1.07982912, -1.13837188,\n",
       "       -1.21554687, -1.20570312, -1.21554687, -1.22539062, -1.13837188,\n",
       "       -0.78498912, -1.22539062, -1.17026562, -1.09372063, -1.20176562,\n",
       "       -1.07982912, -1.22539062, -0.78498912, -1.22539062, -1.20570312,\n",
       "       -0.78498912, -1.20570312, -1.22539062, -1.13837187, -1.10647812,\n",
       "       -1.22539062, -1.21248437, -1.03120887, -1.20570312, -1.21554687,\n",
       "       -1.09372063, -1.17026562, -1.17026562, -0.41298042, -1.22539062,\n",
       "       -0.74365482, -0.88832488, -1.13837187, -1.13837187, -1.19747812,\n",
       "       -1.10647812, -1.17026562, -1.07982912, -1.16317812, -1.22320312,\n",
       "       -1.12844937, -1.04906937, -1.18247188, -1.21554687, -1.20570312,\n",
       "       -1.17026562, -1.17026562, -0.88832488, -0.99166062, -0.88832488,\n",
       "       -1.18798438, -1.21554687, -1.22539062, -1.20176562, -1.22539062,\n",
       "       -1.17026562, -1.22320312, -1.22539062, -1.16317812, -1.20570312,\n",
       "       -1.22539062, -1.21554687, -0.99166062, -1.13837188, -1.13837188,\n",
       "       -1.21835937, -1.22539062, -1.09372063, -0.88832488, -1.13837187,\n",
       "       -1.22539062, -1.07982912, -0.59898477, -1.20176562, -1.04906937,\n",
       "       -1.20570312, -0.88832488, -1.21554687, -1.10647812, -1.22539062,\n",
       "       -1.22539062, -1.22539062, -0.78498912, -1.23242188, -1.16317812,\n",
       "       -1.19747812, -1.22320312, -1.03120887, -1.23242188, -1.20570312,\n",
       "       -1.10647812, -1.07982912, -1.22539062, -1.13837188, -1.23242188,\n",
       "       -1.04906937, -1.23085938, -1.22539062, -1.13837188, -0.94369243,\n",
       "       -0.78498912, -1.16317812, -1.22539062, -1.16317812, -1.21554687,\n",
       "       -1.22539062, -1.03120887, -1.23085938, -1.18798438, -1.03120887,\n",
       "       -1.20176562, -1.21554687, -1.17026562, -1.21554687, -1.22539062,\n",
       "       -1.22539062, -1.17026562, -1.20176562, -0.78498912, -1.22539062,\n",
       "       -1.21554687, -1.17026562, -1.23242188, -1.04906937, -1.17026562,\n",
       "       -1.13837187, -1.09372063, -1.22539062, -1.19747812, -1.18798438,\n",
       "       -1.23085938, -1.22539062, -0.41298042, -1.13837187, -1.20570312,\n",
       "       -1.10647812, -1.10647812, -1.22539062, -1.10647812, -1.22539062,\n",
       "       -1.17026562, -1.22539062, -1.07982912, -1.13837188, -1.13837188,\n",
       "       -1.18247188, -1.22539062, -1.16317812, -1.20176562, -1.10647812,\n",
       "       -1.17026562, -1.20570312, -1.17026562, -1.22539062, -1.23085938,\n",
       "       -1.18247188, -1.20176562, -1.22539062, -1.23242188, -0.88832488,\n",
       "       -1.07982912, -1.13837187, -1.21554687, -1.20176562, -1.22539062,\n",
       "       -1.22539062, -1.17026562, -1.18798438, -1.04906937, -1.13837188,\n",
       "       -0.99166062, -1.18798438, -1.21248437, -1.15546062, -1.18798438,\n",
       "       -1.22539062, -1.22539062, -0.78498912, -1.13837187, -1.10647812,\n",
       "       -1.20570312, -1.20570312, -1.17026562, -1.21554687, -1.23242188,\n",
       "       -1.13837188, -1.10647812, -1.23242188, -0.59898477, -1.13837188,\n",
       "       -1.13837187, -1.21554687, -1.23085938, -1.18247188, -1.13837187,\n",
       "       -1.17026562, -0.78498912, -1.21554687, -0.59898478, -1.13837188,\n",
       "       -1.17026562, -1.22539062, -1.21554687, -1.22539062, -0.41298042,\n",
       "       -1.21554687, -1.22539062, -1.03120887, -1.23085938, -1.20176562,\n",
       "       -1.21554687, -1.13837187, -1.22539062, -1.07982912, -1.13837188,\n",
       "       -1.19747812, -1.18798438, -0.78498912, -1.14748437, -1.20176562,\n",
       "       -1.20176562, -1.20176562, -1.22539062, -1.18798438, -0.99166062,\n",
       "       -1.22539062, -1.22539062, -1.13837188, -1.13837187, -0.59898477,\n",
       "       -1.23085938, -1.22539062, -1.17026562, -1.21554687, -1.09372063,\n",
       "       -1.13837187, -1.21554687, -1.03120887, -1.20570312, -1.22539062,\n",
       "       -1.22539062, -1.09372063, -1.16317812, -1.22539062, -1.20176562,\n",
       "       -1.22539062, -0.78498912, -1.22539062, -1.23242188, -1.20570312,\n",
       "       -0.88832488, -1.21835937, -0.99166062, -1.04906937, -1.13837188,\n",
       "       -1.21248437, -1.22539062, -1.22539062, -1.23242188, -1.13837187,\n",
       "       -1.20570312, -1.12844937, -1.22539062, -1.21554687, -1.14748437,\n",
       "       -1.21554687, -0.99166062, -1.06547187, -0.88832488, -1.13837188,\n",
       "       -1.22320312, -1.22539062, -1.22539062, -1.17026562, -1.16317812,\n",
       "       -1.18798438, -1.06547187, -1.21554687, -1.16317812, -1.13837187,\n",
       "       -1.04906937, -1.22539062, -1.20176562, -0.99166062, -1.17026562,\n",
       "       -1.20570312, -1.16317812, -1.20176562, -1.07982912, -0.99166062,\n",
       "       -1.17026562, -1.22539062, -1.22539062, -1.17026562, -1.17026562,\n",
       "       -1.20176562, -0.88832488, -1.22539062, -1.21554687, -1.20176562,\n",
       "       -1.13837187, -1.22539062, -1.17026562, -1.17026562, -1.15546062,\n",
       "       -1.23242188, -1.18798438, -0.99166062, -1.22539062, -1.17026562,\n",
       "       -1.18798438, -1.18798438, -1.21554687, -1.20570312, -1.03120887,\n",
       "       -1.21554687, -0.91784937, -1.10647812, -1.16317812, -1.20570312,\n",
       "       -1.22539062, -1.22539062, -0.59898477, -1.22539062, -1.22539062,\n",
       "       -1.20570312, -1.04906937, -1.22539062, -1.18798437, -0.59898478,\n",
       "       -1.20570312, -1.22539062, -1.23242188, -1.21554687, -1.20570312,\n",
       "       -1.19747812, -0.59898477, -1.18798438, -1.23242188, -1.10647812,\n",
       "       -0.88832488, -1.12844937, -1.18798438, -0.99166062, -1.17026562,\n",
       "       -1.13837187, -1.20570312, -1.23632812, -1.21248437, -0.99166062,\n",
       "       -1.13837187, -1.20176562, -1.13837187, -1.03120887, -1.10647812,\n",
       "       -1.22539062, -1.20570312, -1.22539062, -0.99166062, -1.17026562,\n",
       "       -1.23242188, -0.94369243, -1.06547187, -1.22539062, -1.22539062,\n",
       "       -1.22539062, -0.78498912, -1.07982912, -1.22539062, -1.17026562,\n",
       "       -1.20176562, -1.22539062, -1.12844937, -1.20176562, -0.88832488,\n",
       "       -1.16317812, -1.04906937, -1.21554687])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6172140430351076\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "ROC-AUC: 0.843206123446067\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('iblm-L6oop2Mj-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67008fb9323ab6c1c90f5d9822582dbef34eff0db475eec3af4e0e9456757ebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
