{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class Classification():\n",
    "    def __init__(\n",
    "        self, \n",
    "        llm_model_name, \n",
    "        params\n",
    "        ):\n",
    "        self.llm_model_name = llm_model_name\n",
    "        self.llm_model = OpenAI(temperature=0, model_name = self.llm_model_name)\n",
    "\n",
    "        #self.llm_model = llm_model,\n",
    "        self.columns_name = params['columns_name']\n",
    "\n",
    "        self.model_code = None\n",
    "\n",
    "    def train(self, x, y, model_name, file_path=None):\n",
    "        print(\"> Start of model training.\")\n",
    "        df = x.copy()\n",
    "\n",
    "        df['target'] = y\n",
    "\n",
    "        # Determine whether binary or multivalued classification is used\n",
    "        if len(df['target'].unique()) == 2:\n",
    "            task_type = 'binary classification'\n",
    "            output_code = 'y = 1 / (1 + np.exp(-y))'\n",
    "        else:\n",
    "            task_type = 'multi-class classification'\n",
    "\n",
    "        # データ型の取得\n",
    "        data_type = ', '.join(df.dtypes.astype(str))\n",
    "\n",
    "\n",
    "\n",
    "        # Create a string dataset\n",
    "        dataset = []\n",
    "        for index, row in df.iterrows():\n",
    "            row_as_str = [str(item) for item in row.tolist()] \n",
    "            dataset.append(','.join(row_as_str))\n",
    "        dataset_str = '\\n'.join(dataset)\n",
    "\n",
    "\n",
    "        # column name\n",
    "        if self.columns_name:\n",
    "            col_name = ', '.join(df.columns.astype(str))\n",
    "\n",
    "        else:\n",
    "            # serial number\n",
    "            df.columns = range(df.shape[1])\n",
    "            col_name = ', '.join(df.columns.astype(str))\n",
    "\n",
    "        create_prompt = \"\"\"\n",
    "        Please create your code in compliance with all of the following conditions. Output should be code only. Do not enclose the output in ``python ``` or the like.\n",
    "        ・Analyze the large amount of data below and create a {task_type_} code to accurately predict \"target\".\n",
    "        ------------------\n",
    "        {dataset_str_}\n",
    "        ------------------\n",
    "        ・Each data type is as follows. If necessary, you can change the data type.\n",
    "        ・Create code that can make predictions about new data based on logic from large amounts of input data without using machine learning models.\n",
    "        ・If input is available, the column names below should also be used to help make decisions when creating the predictive model. Column Name:{col_name_}\n",
    "        ・Create a code like the following. Do not change the input or output format.\n",
    "        ・Use {model_name_} for the function name.\n",
    "        ・You do not need to provide examples.\n",
    "        ------------------\n",
    "        import numpy as np\n",
    "\n",
    "        def model(x):\n",
    "            df = x.copy()\n",
    "\n",
    "            output = []\n",
    "            for index, row in df.iterrows():\n",
    "\n",
    "\n",
    "                # Feature creation and data preprocessing\n",
    "\n",
    "\n",
    "                {output_code_}\n",
    "                output.append(y)\n",
    "\n",
    "            output = np.array(output)\n",
    "                \n",
    "            return output\n",
    "        \"\"\".format(\n",
    "            task_type_ = task_type,\n",
    "            dataset_str_ = dataset_str,\n",
    "            model_name_ = model_name,\n",
    "            col_name_ = col_name,\n",
    "            output_code_ = output_code\n",
    "            )\n",
    "\n",
    "        #print(create_prompt)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            model_code = self.llm_model(create_prompt)\n",
    "            print(cb)\n",
    "\n",
    "\n",
    "        # Save to File\n",
    "        if file_path != None:\n",
    "            with open(file_path + f'{model_name}.py', mode='w') as file:\n",
    "                file.write(model_code)\n",
    "\n",
    "\n",
    "        self.model_code = model_code\n",
    "\n",
    "        return model_code\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.model_code is None:\n",
    "            raise Exception(\"You must train the model before predicting!\")\n",
    "\n",
    "\n",
    "        code = self.model_code + '\\n' + f'model = model({x})'\n",
    "        exec(self.model_code, globals())\n",
    "\n",
    "        #model = namespace[\"code\"]\n",
    "        \n",
    "        y = model(x)\n",
    "\n",
    "        return np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def interpret(self):\n",
    "        if self.model_code is None:\n",
    "            raise Exception(\"You must train the model before interpreting!\")\n",
    "\n",
    "        interpret_prompt = \"\"\"\n",
    "        Refer to the code below and explain how you are going to process the data and make predictions.\n",
    "        The only part to explain is the part where the data is processed.\n",
    "        Do not explain df = x.copy().\n",
    "        Please output the data in bulleted form.\n",
    "        Please tell us what you can say based on the whole process.\n",
    "        ------------------\n",
    "        {model_code_}\n",
    "        \"\"\".format(\n",
    "            model_code_ = self.model_code\n",
    "        )\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            output = self.llm_model(interpret_prompt)\n",
    "            print(cb)\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/learning.csv')\n",
    "x_train = df.drop('survived', axis=1)\n",
    "y_train = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {'columns_name': True}\n",
    "\n",
    "ibl = Classification(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model training.\n",
      "Tokens Used: 4053\n",
      "\tPrompt Tokens: 3411\n",
      "\tCompletion Tokens: 642\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.14085\n"
     ]
    }
   ],
   "source": [
    "model = ibl.train(x_train, y_train, model_name = 'titanic', file_path='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "def titanic(data):\n",
      "    # Convert input data to DataFrame\n",
      "    data = [row.split(',') for row in data.split('\\n')]\n",
      "    columns = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone', 'target']\n",
      "    df = pd.DataFrame(data, columns=columns)\n",
      "    \n",
      "    # Convert data types\n",
      "    df['pclass'] = df['pclass'].astype(int)\n",
      "    df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
      "    df['sibsp'] = df['sibsp'].astype(int)\n",
      "    df['parch'] = df['parch'].astype(int)\n",
      "    df['fare'] = pd.to_numeric(df['fare'], errors='coerce')\n",
      "    df['target'] = df['target'].astype(int)\n",
      "    \n",
      "    # Feature creation and data preprocessing\n",
      "    df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
      "    df['embarked'] = df['embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
      "    df['class'] = df['class'].map({'First': 1, 'Second': 2, 'Third': 3})\n",
      "    df['who'] = df['who'].map({'man': 0, 'woman': 1, 'child': 2})\n",
      "    df['adult_male'] = df['adult_male'].map({True: 1, False: 0})\n",
      "    df['alone'] = df['alone'].map({True: 1, False: 0})\n",
      "    \n",
      "    # Fill missing values\n",
      "    df['age'].fillna(df['age'].median(), inplace=True)\n",
      "    df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
      "    df['fare'].fillna(df['fare'].median(), inplace=True)\n",
      "    \n",
      "    # Predictive model\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "        y = 0\n",
      "        \n",
      "        # Weights for features\n",
      "        y += -0.5 * row['pclass']\n",
      "        y += 1.5 * row['sex']\n",
      "        y += -0.02 * row['age']\n",
      "        y += -0.3 * row['sibsp']\n",
      "        y += 0.1 * row['parch']\n",
      "        y += 0.01 * row['fare']\n",
      "        y += 0.2 * row['embarked']\n",
      "        y += -0.5 * row['class']\n",
      "        y += 1.5 * row['who']\n",
      "        y += -1.5 * row['adult_male']\n",
      "        y += 0.3 * row['alone']\n",
      "        \n",
      "        # Apply logistic function\n",
      "        y = 1 / (1 + np.exp(-y))\n",
      "        output.append(y)\n",
      "    \n",
      "    output = np.array(output)\n",
      "    \n",
      "    return output\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pred.csv')\n",
    "x_test = df.drop('survived', axis=1)\n",
    "y_test = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m \u001b[43mibl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_proba \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[0;32mIn[70], line 126\u001b[0m, in \u001b[0;36mClassification.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m exec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_code, \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m#model = namespace[\"code\"]\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(y)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "y_proba = ibl.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41\n",
      "Precision: 0.37894736842105264\n",
      "Recall: 1.0\n",
      "F1 score: 0.549618320610687\n",
      "ROC-AUC: 0.9309895833333334\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction from external files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtitanic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m titanic\n\u001b[0;32m----> 3\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_proba \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from titanic import titanic\n",
    "\n",
    "y_proba = model(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41\n",
      "Precision: 0.37894736842105264\n",
      "Recall: 1.0\n",
      "F1 score: 0.549618320610687\n",
      "ROC-AUC: 0.9309895833333334\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 1065\n",
      "\tPrompt Tokens: 552\n",
      "\tCompletion Tokens: 513\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04733999999999999\n"
     ]
    }
   ],
   "source": [
    "description = ibl.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data processing and prediction steps in the given code can be explained as follows:\n",
      "\n",
      "- Preprocessing:\n",
      "    - Convert the 'sex' column to numerical values: male = 0, female = 1\n",
      "    - Fill missing values in the 'age' column with the median age\n",
      "    - Fill missing values in the 'fare' column with the median fare\n",
      "    - Convert the 'embarked' column to numerical values: S = 0, C = 1, Q = 2\n",
      "    - Convert the 'class' column to numerical values: First = 1, Second = 2, Third = 3\n",
      "    - Convert the 'who' column to numerical values: man = 0, woman = 1, child = 2\n",
      "    - Convert the 'adult_male' column to integer values\n",
      "    - Convert the 'alone' column to integer values\n",
      "\n",
      "- For each row in the DataFrame:\n",
      "    - Extract the values of the following features: pclass, sex, age, sibsp, parch, fare, embarked, who, adult_male, alone\n",
      "    - Initialize the prediction variable 'y' to 0\n",
      "    - Apply the prediction logic:\n",
      "        - If the passenger is female, add 1 to 'y'\n",
      "        - If the passenger is in first class, add 0.5 to 'y'; if in second class, add 0.25\n",
      "        - If the passenger's age is less than or equal to 16, add 0.5 to 'y'\n",
      "        - If the passenger's fare is greater than the median fare, add 0.25 to 'y'\n",
      "        - If the passenger embarked at port C, add 0.25 to 'y'\n",
      "        - If the passenger is a woman or child, add 0.5 to 'y'\n",
      "        - If the passenger is not an adult male, add 0.25 to 'y'\n",
      "        - If the passenger is alone, add 0.25 to 'y'\n",
      "    - Calculate the final prediction value using the logistic function: y = 1 / (1 + exp(-y))\n",
      "    - Append the prediction value to the output list\n",
      "\n",
      "Based on the whole process, we can say that the model takes into account various features of the passengers, such as their sex, age, class, fare, and whether they are alone or not, to make predictions. The model uses a simple linear combination of these features followed by a logistic function to produce the final prediction values.\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "# データフレームのカラム名を連続する整数に置き換えます。\n",
    "df.columns = range(df.shape[1])\n",
    "\n",
    "# 結果を表示します。\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
