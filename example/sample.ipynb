{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class Classification():\n",
    "    def __init__(\n",
    "        self, \n",
    "        llm_model_name, \n",
    "        params\n",
    "        ):\n",
    "        self.llm_model_name = llm_model_name\n",
    "        self.llm_model = OpenAI(temperature=0, model_name = self.llm_model_name)\n",
    "\n",
    "        #self.llm_model = llm_model,\n",
    "        self.columns_name = params['columns_name']\n",
    "\n",
    "        self.model_code = None\n",
    "\n",
    "    def train(self, x, y, model_name, file_path=None):\n",
    "        print(\"> Start of model training.\")\n",
    "        df = x.copy()\n",
    "\n",
    "        # yのデータをtargetとしてxのdataframeに加える\n",
    "        df['target'] = y\n",
    "\n",
    "        # 二値分類か多値分類かを判定\n",
    "        if len(df['target'].unique()) == 2:\n",
    "            task_type = 'binary classification'\n",
    "            output_code = 'y = 1 / (1 + np.exp(-y))'\n",
    "        else:\n",
    "            task_type = 'multi-class classification'\n",
    "\n",
    "        # データ型の取得\n",
    "        data_type = ', '.join(df.dtypes.astype(str))\n",
    "\n",
    "\n",
    "\n",
    "        # 文字列のdatasetを作成\n",
    "        dataset = []\n",
    "        for index, row in df.iterrows():\n",
    "            row_as_str = [str(item) for item in row.tolist()]  # 各要素を文字列に変換\n",
    "            dataset.append(','.join(row_as_str))\n",
    "\n",
    "        # リスト全体を改行文字で結合\n",
    "        dataset_str = '\\n'.join(dataset)\n",
    "\n",
    "\n",
    "        # ハイパーパラメータの設定\n",
    "        if self.columns_name:\n",
    "            col_name = ', '.join(df.columns.astype(str))\n",
    "\n",
    "        else:\n",
    "            col_name = None\n",
    "\n",
    "        create_prompt = \"\"\"\n",
    "        Please create your code in compliance with all of the following conditions. Output should be code only. Do not enclose the output in ``python ``` or the like.\n",
    "        ・Analyze the large amount of data below and create a {task_type_} code to accurately predict \"target\".\n",
    "        ------------------\n",
    "        {dataset_str_}\n",
    "        ------------------\n",
    "        ・Each data type is as follows. If necessary, you can change the data type.\n",
    "        ・Create code that can make predictions about new data based on logic from large amounts of input data without using machine learning models.\n",
    "        ・If input is available, the column names below should also be used to help make decisions when creating the predictive model. Column Name:{col_name_}\n",
    "        ・Create a code like the following. Do not change the input or output format.\n",
    "        ・Use {model_name_} for the function name.\n",
    "        ・You do not need to provide examples.\n",
    "        ------------------\n",
    "        import numpy as np\n",
    "\n",
    "        def model(x):\n",
    "            df = x.copy()\n",
    "\n",
    "            output = []\n",
    "            for index, row in df.iterrows():\n",
    "\n",
    "\n",
    "                # Feature creation and data preprocessing\n",
    "\n",
    "\n",
    "                {output_code_}\n",
    "                output.append(y)\n",
    "                \n",
    "            return output\n",
    "        \"\"\".format(\n",
    "            task_type_ = task_type,\n",
    "            dataset_str_ = dataset_str,\n",
    "            model_name_ = model_name,\n",
    "            col_name_ = col_name,\n",
    "            output_code_ = output_code\n",
    "            )\n",
    "\n",
    "        #print(create_prompt)\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            model_code = self.llm_model(create_prompt)\n",
    "            print(model_code)\n",
    "            print(cb)\n",
    "\n",
    "\n",
    "        # Save to File\n",
    "        if file_path != None:\n",
    "            with open(file_path + f'{model_name}.py', mode='w') as file:\n",
    "                file.write(model_code)\n",
    "\n",
    "\n",
    "        self.model_code = model_code\n",
    "\n",
    "        return model_code\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.model_code is None:\n",
    "            raise Exception(\"You must train the model before predicting!\")\n",
    "\n",
    "\n",
    "        #code = self.model_code + '\\n' + f'model = model({x})'\n",
    "        exec(self.model_code, globals())\n",
    "\n",
    "        #model = namespace[\"code\"]\n",
    "        \n",
    "        y = model(x)\n",
    "\n",
    "        return np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def interpret(self):\n",
    "        if self.model_code is None:\n",
    "            raise Exception(\"You must train the model before interpreting!\")\n",
    "\n",
    "        interpret_prompt = \"\"\"\n",
    "        Refer to the code below and explain how you are going to process the data and make predictions.\n",
    "        The only part to explain is the part where the data is processed.\n",
    "        Do not explain df = x.copy().\n",
    "        Please output the data in bulleted form.\n",
    "        Please tell us what you can say based on the whole process.\n",
    "        ------------------\n",
    "        {model_code_}\n",
    "        \"\"\".format(\n",
    "            model_code_ = self.model_code\n",
    "        )\n",
    "\n",
    "        with get_openai_callback() as cb:\n",
    "            output = self.llm_model(interpret_prompt)\n",
    "            print(cb)\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/learning.csv')\n",
    "x_train = df.drop('survived', axis=1)\n",
    "y_train = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4'\n",
    "\n",
    "params = {'columns_name': True}\n",
    "\n",
    "ibl = Classification(llm_model_name=llm_model_name, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start of model training.\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "def titanic(data):\n",
      "    df = pd.DataFrame(data, columns=[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"Deck\", \"Title\", \"Alone\", \"Cabin\", \"Embark_town\", \"Alive\", \"IsAlone\", \"Target\"])\n",
      "\n",
      "    output = []\n",
      "    for index, row in df.iterrows():\n",
      "\n",
      "        # Feature creation and data preprocessing\n",
      "        sex = 1 if row[\"Sex\"] == \"male\" else 0\n",
      "        age = row[\"Age\"]\n",
      "        if pd.isna(age):\n",
      "            age = 30\n",
      "        fare = row[\"Fare\"]\n",
      "        if pd.isna(fare):\n",
      "            fare = 14\n",
      "        pclass = row[\"Pclass\"]\n",
      "        sibsp = row[\"SibSp\"]\n",
      "        parch = row[\"Parch\"]\n",
      "        embarked = 0\n",
      "        if row[\"Embarked\"] == \"C\":\n",
      "            embarked = 1\n",
      "        elif row[\"Embarked\"] == \"Q\":\n",
      "            embarked = 2\n",
      "\n",
      "        # Prediction logic\n",
      "        y = -1.5 + 0.1 * sex - 0.02 * age + 0.15 * fare - 0.5 * pclass + 0.3 * sibsp - 0.1 * parch + 0.2 * embarked\n",
      "\n",
      "        y = 1 / (1 + np.exp(-y))\n",
      "        output.append(y)\n",
      "        \n",
      "    return output\n",
      "Tokens Used: 3690\n",
      "\tPrompt Tokens: 3371\n",
      "\tCompletion Tokens: 319\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.12027\n"
     ]
    }
   ],
   "source": [
    "model = ibl.train(x_train, y_train, model_name = 'titanic', file_path='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pred.csv')\n",
    "x_test = df.drop('survived', axis=1)\n",
    "y_test = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_proba \u001b[38;5;241m=\u001b[39m \u001b[43mibl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_proba \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 124\u001b[0m, in \u001b[0;36mClassification.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    120\u001b[0m exec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_code, \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m#model = namespace[\"code\"]\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(y)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "y_proba = ibl.predict(x_test)\n",
    "y_pred = (y_proba > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.41\n",
      "Precision: 0.37894736842105264\n",
      "Recall: 1.0\n",
      "F1 score: 0.549618320610687\n",
      "ROC-AUC: 0.9309895833333334\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1 score: {f1}')\n",
    "\n",
    "# ROC-AUC (you need prediction probabilities for this, not just class predictions)\n",
    "# Here we just reuse y_pred for simplicity\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC-AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction from external files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import model\n",
    "\n",
    "y_proba = model(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 1065\n",
      "\tPrompt Tokens: 552\n",
      "\tCompletion Tokens: 513\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.04733999999999999\n"
     ]
    }
   ],
   "source": [
    "description = ibl.interpret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data processing and prediction steps in the given code can be explained as follows:\n",
      "\n",
      "- Preprocessing:\n",
      "    - Convert the 'sex' column to numerical values: male = 0, female = 1\n",
      "    - Fill missing values in the 'age' column with the median age\n",
      "    - Fill missing values in the 'fare' column with the median fare\n",
      "    - Convert the 'embarked' column to numerical values: S = 0, C = 1, Q = 2\n",
      "    - Convert the 'class' column to numerical values: First = 1, Second = 2, Third = 3\n",
      "    - Convert the 'who' column to numerical values: man = 0, woman = 1, child = 2\n",
      "    - Convert the 'adult_male' column to integer values\n",
      "    - Convert the 'alone' column to integer values\n",
      "\n",
      "- For each row in the DataFrame:\n",
      "    - Extract the values of the following features: pclass, sex, age, sibsp, parch, fare, embarked, who, adult_male, alone\n",
      "    - Initialize the prediction variable 'y' to 0\n",
      "    - Apply the prediction logic:\n",
      "        - If the passenger is female, add 1 to 'y'\n",
      "        - If the passenger is in first class, add 0.5 to 'y'; if in second class, add 0.25\n",
      "        - If the passenger's age is less than or equal to 16, add 0.5 to 'y'\n",
      "        - If the passenger's fare is greater than the median fare, add 0.25 to 'y'\n",
      "        - If the passenger embarked at port C, add 0.25 to 'y'\n",
      "        - If the passenger is a woman or child, add 0.5 to 'y'\n",
      "        - If the passenger is not an adult male, add 0.25 to 'y'\n",
      "        - If the passenger is alone, add 0.25 to 'y'\n",
      "    - Calculate the final prediction value using the logistic function: y = 1 / (1 + exp(-y))\n",
      "    - Append the prediction value to the output list\n",
      "\n",
      "Based on the whole process, we can say that the model takes into account various features of the passengers, such as their sex, age, class, fare, and whether they are alone or not, to make predictions. The model uses a simple linear combination of these features followed by a logistic function to produce the final prediction values.\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
