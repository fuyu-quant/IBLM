Here is a simple Python code that uses a logistic regression model to predict the probability that the "target" of the unknown data is 1. This code assumes that the input data is a pandas DataFrame with columns named 'Feature_1', 'Feature_2', and 'target'.

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression

# Prepare the data
data = [
    [1.342,-0.412,1.0], [2.029,0.302,1.0], [0.532,-0.396,1.0], [0.021,0.333,1.0], [1.731,-0.241,1.0],
    [0.753,-0.613,1.0], [1.957,0.304,1.0], [1.209,-0.53,1.0], [1.689,-0.229,1.0], [0.06,0.525,1.0],
    [0.731,-0.436,1.0], [0.256,-0.106,1.0], [1.516,-0.398,1.0], [0.749,-0.513,1.0], [0.084,0.316,1.0],
    [1.643,-0.379,1.0], [1.28,-0.498,1.0], [1.998,0.356,1.0], [0.986,-0.413,1.0], [0.095,0.099,1.0],
    [1.878,0.06,1.0], [0.094,-0.052,1.0], [1.56,-0.322,1.0], [0.582,-0.449,1.0], [0.481,-0.398,1.0],
    [1.991,0.284,1.0], [0.091,0.222,1.0], [0.985,-0.464,1.0], [-0.008,0.469,1.0], [2.011,0.462,1.0],
    [0.537,-0.407,1.0], [1.591,-0.253,1.0], [0.558,-0.311,1.0], [1.825,-0.107,1.0], [1.289,-0.474,1.0],
    [0.155,0.107,1.0], [0.181,-0.078,1.0], [0.64,-0.396,1.0], [1.809,-0.166,1.0], [0.12,0.01,1.0],
    [0.094,0.067,1.0], [0.102,0.043,1.0], [1.178,-0.45,1.0], [1.937,0.266,1.0], [1.147,-0.452,1.0],
    [0.527,-0.379,1.0], [0.88,-0.47,1.0], [1.956,0.16,1.0], [-0.022,0.499,1.0], [0.09,0.165,1.0],
    [0.016,0.237,1.0], [1.808,-0.087,1.0], [0.713,-0.48,1.0], [0.218,-0.059,1.0], [1.7,-0.16,1.0],
    [1.558,-0.283,1.0], [0.433,-0.286,1.0], [0.877,-0.511,1.0], [1.979,0.323,1.0], [1.19,-0.311,1.0],
    [0.185,-0.164,1.0], [0.355,-0.374,1.0], [1.975,0.268,1.0], [1.611,-0.266,1.0], [0.663,-0.401,1.0],
    [0.075,0.317,1.0], [0.366,-0.366,1.0], [1.976,0.308,1.0], [1.463,-0.274,1.0], [0.034,0.251,1.0],
    [0.205,-0.024,1.0], [-0.071,0.34,1.0], [0.731,-0.436,1.0], [0.79,-0.499,1.0], [-0.061,0.476,1.0],
    [0.879,-0.541,1.0], [2.062,0.436,1.0], [1.694,-0.308,1.0], [1.419,-0.424,1.0], [0.001,0.413,1.0],
    [0.852,-0.547,1.0], [0.189,0.009,1.0], [0.348,-0.333,1.0], [2.036,0.422,1.0], [1.98,0.483,1.0],
    [0.078,0.146,1.0], [2.032,0.474,1.0], [1.984,0.172,1.0], [1.803,-0.087,1.0], [1.916,0.077,1.0],
    [0.856,-0.483,1.0], [0.658,-0.389,1.0], [1.872,-0.074,1.0], [0.026,0.239,1.0], [0.26,-0.188,1.0],
    [0.063,0.281,1.0], [2.067,0.461,1.0], [0.667,-0.448,1.0], [1.87,0.023,1.0], [1.466,-0.368,1.0]
]
df = pd.DataFrame(data, columns=['Feature_1', 'Feature_2', 'target'])

# Split the data into features and target
X = df[['Feature_1', 'Feature_2']]
y = df['target']

# Train the model
model = LogisticRegression()
model.fit(X, y)

def predict(x):
    df = x.copy()
    output = model.predict_proba(df[['Feature_1', 'Feature_2']])[:, 1]
    return output
```

This code first prepares the data and splits it into features (X) and target (y). It then trains a logistic regression model on this data. The `predict` function takes a DataFrame as input, makes a copy of it, and uses the trained model to predict the probability that the "target" is 1 for each row in the DataFrame. The output is an array of probabilities.