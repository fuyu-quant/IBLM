Here is a simple Python code that uses a linear regression model to predict the probability of the target being 1. This code assumes that the input 'x' is a pandas DataFrame with columns 'Feature_1' and 'Feature_2'.

```python
import numpy as np
import pandas as pd

# Define the data
data = pd.DataFrame({
    'Feature_1': [0.059, 0.203, -0.016, -0.858, 1.634, -0.52, 1.909, 1.05, 0.121, 0.91, 0.39, -0.229, 0.226, -0.632, 0.075, -1.045, 0.38, -0.895, 1.87, 0.461, 1.01, -0.26, 1.989, -0.854, 1.976, 0.065, 0.109, -0.884, 0.28, 0.004, 2.007, -0.772, 0.395, 0.759, 0.207, 0.18, 0.748, 0.725, 0.426, -0.877, 1.995, -0.715, 0.83, -0.819, 0.02, -0.533, 2.029, -1.142, 1.655, 0.924, 0.797, -0.852, 1.941, 0.54, 1.749, -1.031, 1.152, -1.012, 0.097, 0.983, 0.308, -0.862, -0.048, 0.543, 1.636, 0.756, 0.299, -0.817, 1.644, 0.784, 1.983, 0.902, 0.279, 1.054, 0.089, 0.909, 1.477, -0.889, 0.007, 0.317, 0.163, -1.026, 1.785, 0.051, 0.557, -0.397, 1.704, -0.944, 1.481, -0.051, 0.587, 0.12, 0.163, -0.833, 0.815, -0.144, 0.25, -0.872, 1.419, 0.365, 0.487, 0.759, 0.095, -0.438, 1.25, 0.963, 1.928, 0.967, 0.026, 0.466, 1.913, -0.925, 0.239, -0.566, 0.36, -0.84, 1.343, 0.052, -0.045, -0.632, 2.015, 1.042, 1.798, 0.195, 1.809, -0.709, 0.659, 0.127, 0.327, -0.266, 0.466, -0.847, 0.752, 0.213, 1.863, 0.755, 1.65, -0.094, 0.128, 0.92, 0.266, 0.555, 1.282, 0.83, 1.474, -0.909, 0.582, 0.495, 1.279, 1.103, 0.752, -1.021, 2.09, 0.372, 1.816, 0.93, 1.697, -0.398, 0.699, 0.859, 1.314, -0.488, 2.002, -0.875, 1.463, -0.185, 0.47, -0.864, 0.638, 0.844, 1.716, 0.13, 1.61, 0.93, 1.843, 0.034, 0.059, 0.579, 0.183, 1.88, -0.981, 1.243, 0.051, 0.014, 0.604, -0.005, -0.115, 0.818, -0.727, 1.693, 0.579, -0.047, -0.95, 1.135, 0.605, 0.383, -0.017, 0.609, 1.03, 2.074, 0.666, 1.929, 0.72, 1.796, -0.512, 0.802, -0.646, 1.335, -0.233, 1.204, -0.762, 0.201, 0.529, 1.802, 0.79, 1.718, -0.689, 1.948, 0.957, 1.961, 0.774, 1.266, 1.047, 1.605, 0.33, 1.056, -0.978, 1.188, 0.862, 0.842, -0.488, 0.91, 0.945, 1.731, -0.954, 1.763, -0.853, 0.021, -0.646, 1.957, -1.028, 1.588, 0.355, 2.056, -0.652, 1.876, 0.65, 0.43, 1.027, 0.727, 0.973, 1.387, 0.169, 0.92, 0.824, 1.684, -0.521, 0.118, 0.683, 0.625, 0.508, 0.277, 1.013, -0.031, 1.314, 0.383, 1.956, -0.675, 0.222, 0.935, 0.045, -0.998, 0.213, 1.088, 0.109, 0.952, 0.481, 0.951, 1.975, 0.771, 1.896, -0.718, 0.008, -0.887, 1.683, 0.314, 0.982, -0.158, 0.907, 0.877, 0.111, 0.68, 1.998, -0.054, 0.694, -0.858, 0.504, 0.974],
    'Feature_2': [0.2, 0.944, 0.375, 0.617, -0.302, 0.975, 0.038, 0.149, 0.163, 0.419, -0.299, 0.959, -0.153, 0.769, 0.075, 0.185, -0.31, 0.425, 0.074, 0.849, -0.535, 0.915, 0.135, 0.397, 0.191, 0.977, 0.109, 0.339, -0.288, 0.972, 0.231, 0.586, -0.351, 0.736, -0.137, 1.003, -0.418, 0.651, -0.32, 0.431, 0.393, 0.661, -0.516, 0.587, 0.366, 0.785, 0.2, 0.108, -0.233, -0.07, -0.498, 0.441, 0.358, 0.88, -0.112, 0.264, -0.459, 0.256, -0.156, 0.037, -0.216, 0.547, 0.259, 0.873, -0.179, 0.621, -0.329, 0.594, -0.235, 0.639, 0.406, 0.093, -0.117, 0.123, 0.347, 0.283, -0.213, 0.372, 0.355, 0.838, -0.045, 0.248, 0.024, 0.993, -0.356, 0.937, -0.249, 0.516, -0.449, 0.966, -0.448, 1.003, -0.056, 0.452, -0.498, 0.959, -0.179, 0.544, -0.413, 0.983, -0.359, 0.643, 0.339, 0.822, -0.38, 0.075, 0.109, 0.258, 0.095, 0.814, 0.014, 0.452, -0.099, 0.854, -0.254, 0.561, -0.397, 0.969, 0.326, 0.842, 0.074, 0.072, -0.034, 0.938, -0.171, 0.717, -0.476, 0.913, -0.104, 0.898, -0.466, 0.555, -0.426, 0.953, 0.363, 0.668, -0.269, 0.995, -0.019, 0.314, -0.139, 0.83, -0.42, 0.475, -0.307, 0.328, -0.521, 0.908, -0.413, 0.152, -0.397, 0.255, 0.46, 0.854, -0.095, 0.245, -0.195, 0.857, -0.506, 0.41, -0.498, 0.908, 0.204, 0.675, -0.348, 1.034, -0.388, 0.484, -0.501, 0.434, -0.157, 0.982, -0.354, 0.234, -0.149, 0.959, 0.314, 0.966, 0.916, 0.028, -0.052, -0.536, 1.06, 0.217, 0.827, 0.174, 1.012, -0.479, 0.759, -0.365, 0.804, 0.476, 0.123, -0.467, 0.869, -0.245, 0.988, -0.461, 0.357, 0.333, 0.789, 0.454, 0.592, -0.118, 0.786, -0.515, 0.812, -0.352, 0.972, -0.487, 0.589, -0.067, 0.858, 0.011, 0.741, -0.284, 0.8, 0.275, 0.259, 0.279, 0.579, -0.39, 0.1, -0.293, 0.948, -0.394, 0.166, -0.456, 0.553, -0.462, 0.835, -0.515, 0.405, -0.164, 0.307, 0.032, 0.111, 0.276, 0.836, 0.278, 0.212, -0.333, 0.917, 0.412, 0.839, 0.072, 0.723, -0.387, 0.289, -0.441, 0.051, -0.47, 1.007, -0.463, 0.684, -0.146, 0.936, 0.07, 0.677, -0.449, 0.882, -0.176, -0.032, 0.402, 0.226, -0.501, 0.965, 0.386, 0.884, -0.064, 0.232, 0.392, 0.035, -0.15, 0.14, 0.011, 0.058, -0.31, 0.151, 0.394, 0.511, 0.491, 0.731, 0.228, 0.121, -0.213, 0.922, -0.46, 1.001, -0.438, 0.373, -0.047, 0.722, 0.386, 0.884, -0.49, 0.421, -0.311, 0.974],
    'target': [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0